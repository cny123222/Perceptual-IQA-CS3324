# All 14 Experiment Commands (Individual)

**Date**: 2025-12-22  
**Configuration**: batch_size=32, epochs=5, train_test_num=1  
**Baseline**: Alpha=0.3 (SRCC 0.9352)

**å»ºè®®è¿è¡Œæ–¹å¼**ï¼š
- **ä¸€æ¬¡è·‘1ä¸ªå®éªŒ**ï¼šæœ€å¿«ï¼Œæ— èµ„æºç«äº‰
- **ä¸€æ¬¡è·‘2ä¸ªå®éªŒ**ï¼šå¯æ¥å—ï¼Œæ³¨æ„åˆ†é…ä¸åŒGPU
- âŒ ä¸å»ºè®®4ä¸ªåŒæ—¶è·‘ï¼šä¼šå¾ˆæ…¢ï¼

---

## A. Core Ablations (æ ¸å¿ƒæ¶ˆè)

### A1: ç§»é™¤Attention Fusion

**ç›®çš„**: éªŒè¯Attention Fusionçš„è´¡çŒ®

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### A2: ç§»é™¤Ranking Loss (Alpha=0)

**ç›®çš„**: éªŒè¯Ranking Lossçš„è´¡çŒ®

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### A3: ç§»é™¤Multi-scale Feature Fusion

**ç›®çš„**: éªŒè¯Multi-scaleçš„è´¡çŒ®

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --no_multiscale \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

## C. Ranking Loss Sensitivity (Ranking Lossçµæ•åº¦)

### C1: Alpha=0.1 (Lower)

**ç›®çš„**: æµ‹è¯•è¾ƒä½çš„ranking lossæƒé‡

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.1 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### C2: Alpha=0.5 (Higher)

**ç›®çš„**: æµ‹è¯•è¾ƒé«˜çš„ranking lossæƒé‡ï¼ˆåŸbesté…ç½®ï¼‰

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.5 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### C3: Alpha=0.7 (Much Higher)

**ç›®çš„**: æµ‹è¯•æ›´é«˜çš„ranking lossæƒé‡

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.7 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

## B. Model Size Comparison (æ¨¡å‹å¤§å°å¯¹æ¯”)

### B1: Swin-Tiny (~28M params)

**ç›®çš„**: æµ‹è¯•æ›´å°çš„æ¨¡å‹

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size tiny \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### B2: Swin-Small (~50M params)

**ç›®çš„**: æµ‹è¯•ä¸­ç­‰å¤§å°çš„æ¨¡å‹

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size small \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

## D. Weight Decay Sensitivity (æ­£åˆ™åŒ–å¼ºåº¦)

### D1: Weight Decay=5e-5 (Very Weak, 0.25Ã—)

**ç›®çš„**: æµ‹è¯•éå¸¸å¼±çš„æ­£åˆ™åŒ–

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 5e-5 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### D2: Weight Decay=1e-4 (Weak, 0.5Ã—)

**ç›®çš„**: æµ‹è¯•è¾ƒå¼±çš„æ­£åˆ™åŒ–

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 1e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### D4: Weight Decay=4e-4 (Strong, 2Ã—)

**ç›®çš„**: æµ‹è¯•è¾ƒå¼ºçš„æ­£åˆ™åŒ–

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 5e-6 \
  --weight_decay 4e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

## E. Learning Rate Sensitivity (å­¦ä¹ ç‡çµæ•åº¦)

### E1: LR=2.5e-6 (Conservative, 0.5Ã—)

**ç›®çš„**: æµ‹è¯•æ›´ä¿å®ˆçš„å­¦ä¹ ç‡

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 2.5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### E3: LR=7.5e-6 (Faster, 1.5Ã—)

**ç›®çš„**: æµ‹è¯•æ›´å¿«çš„å­¦ä¹ ç‡

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 7.5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

### E4: LR=1e-5 (Aggressive, 2Ã—)

**ç›®çš„**: æµ‹è¯•æ¿€è¿›çš„å­¦ä¹ ç‡

```bash
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 5 \
  --patience 5 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --train_test_num 1 \
  --attention_fusion \
  --ranking_loss_alpha 0.3 \
  --lr 1e-5 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

---

## ğŸ“‹ å®éªŒè¿è¡Œå»ºè®®

### æ–¹å¼1ï¼šé¡ºåºè¿è¡Œï¼ˆæœ€ç¨³å®šï¼‰

**ä¸€æ¬¡è·‘1ä¸ªï¼Œå®Œæˆåå†è·‘ä¸‹ä¸€ä¸ª**

```bash
# å…ˆè·‘A1ï¼Œç­‰å®ƒå®Œæˆ
# ç„¶åè·‘A2ï¼Œç­‰å®ƒå®Œæˆ
# ...
```

**ä¼˜ç‚¹**: é€Ÿåº¦æœ€å¿«ï¼Œæ— GPUç«äº‰  
**ç¼ºç‚¹**: éœ€è¦æ‰‹åŠ¨ç›‘æ§  
**é¢„è®¡æ—¶é—´**: æ¯ä¸ª5-10åˆ†é’Ÿï¼Œæ€»å…±1.5-2å°æ—¶

---

### æ–¹å¼2ï¼šåŒGPUå¹¶è¡Œï¼ˆæ¨èï¼‰

**ä¸€æ¬¡è·‘2ä¸ªï¼Œç”¨ä¸åŒçš„GPU**

```bash
# Terminal 1 - GPU 0
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py ...

# Terminal 2 - GPU 1
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=1 python train_swin.py ...
```

**ä¼˜ç‚¹**: é€Ÿåº¦è¾ƒå¿«ï¼Œå¯æ¥å—çš„èµ„æºç«äº‰  
**ç¼ºç‚¹**: éœ€è¦å¼€ä¸¤ä¸ªterminal  
**é¢„è®¡æ—¶é—´**: æ¯å¯¹8-12åˆ†é’Ÿï¼Œæ€»å…±1-1.5å°æ—¶

---

### æ–¹å¼3ï¼štmuxåå°è¿è¡Œ

**ç”¨tmuxè¿è¡Œï¼Œå¯ä»¥å…³é—­SSH**

```bash
# åˆ›å»ºtmuxä¼šè¯
tmux new-session -s exp1

# è¿è¡Œå®éªŒ
cd /root/Perceptual-IQA-CS3324 && CUDA_VISIBLE_DEVICES=0 python train_swin.py ...

# æŒ‰ Ctrl+B ç„¶å D é€€å‡ºtmuxï¼ˆå®éªŒç»§ç»­è¿è¡Œï¼‰

# é‡æ–°è¿æ¥
tmux attach-session -s exp1
```

---

## ğŸ“Š å®éªŒé¡ºåºå»ºè®®

### ä¼˜å…ˆçº§1ï¼šæ ¸å¿ƒæ¶ˆèï¼ˆå¿…é¡»ï¼‰
1. **A1** - ç§»é™¤Attention ï¼ˆæœ€é‡è¦ï¼‰
2. **A2** - ç§»é™¤Ranking ï¼ˆæœ€é‡è¦ï¼‰
3. **A3** - ç§»é™¤Multi-scale ï¼ˆæœ€é‡è¦ï¼‰

### ä¼˜å…ˆçº§2ï¼šRankingçµæ•åº¦
4. **C1** - Alpha=0.1
5. **C2** - Alpha=0.5
6. **C3** - Alpha=0.7

### ä¼˜å…ˆçº§3ï¼šæ¨¡å‹å¤§å°
7. **B1** - Swin-Tiny
8. **B2** - Swin-Small

### ä¼˜å…ˆçº§4ï¼šæ­£åˆ™åŒ–çµæ•åº¦
9. **D1** - WD=5e-5
10. **D2** - WD=1e-4
11. **D4** - WD=4e-4

### ä¼˜å…ˆçº§5ï¼šå­¦ä¹ ç‡çµæ•åº¦
12. **E1** - LR=2.5e-6
13. **E3** - LR=7.5e-6
14. **E4** - LR=1e-5

---

## âœ… å‚æ•°éªŒè¯

æ‰€æœ‰14ä¸ªå‘½ä»¤éƒ½åŒ…å«ï¼š
- âœ… `--batch_size 32`
- âœ… `--epochs 5`
- âœ… `--train_test_num 1`
- âœ… `--patience 5`
- âœ… `--train_patch_num 20`
- âœ… `--test_patch_num 20`
- âœ… `--lr_scheduler cosine`
- âœ… `--test_random_crop`
- âœ… `--no_spaq`

æ¯ä¸ªå®éªŒåªæ”¹å˜ä¸€ä¸ªç›®æ ‡å‚æ•°ï¼

---

## ğŸ” ç›‘æ§å‘½ä»¤

### æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
```bash
watch -n 1 nvidia-smi
```

### æŸ¥çœ‹æœ€æ–°æ—¥å¿—
```bash
tail -f logs/swin_*.log
```

### æŸ¥çœ‹æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„å®éªŒ
```bash
ps aux | grep train_swin.py
```

---

## ğŸ“ å®Œæˆå

è®°å¾—å°†æ‰€æœ‰ç»“æœè®°å½•åˆ° `VALIDATION_AND_ABLATION_LOG.md`ï¼

æ¯ä¸ªå®éªŒè®°å½•ï¼š
- å®éªŒåç§°
- SRCC
- PLCC
- RMSE
- å˜åŒ–çš„å‚æ•°

