"""
ç‰¹å¾å›¾çƒ­åŠ›å›¾å¯è§†åŒ–
æ˜¾ç¤ºåŒä¸€å›¾åƒåœ¨4ä¸ªSwin Transformer stageçš„ç‰¹å¾æ¿€æ´»
"""
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['pdf.fonttype'] = 42
matplotlib.rcParams['ps.fonttype'] = 42
from PIL import Image
import torchvision.transforms as transforms
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import models_swin as models


class FeatureExtractor:
    """æå–Swin Transformerå„ä¸ªstageçš„ç‰¹å¾å›¾"""
    
    def __init__(self, model_path, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        print(f"Loading model from: {model_path}")
        checkpoint = torch.load(model_path, map_location=self.device)
        
        self.model = models.HyperNet(
            16, 112, 224, 112, 56, 28, 14, 7,
            use_multiscale=True,
            use_attention=True,
            model_size='base'
        ).to(self.device)
        
        if 'model' in checkpoint:
            self.model.load_state_dict(checkpoint['model'])
        else:
            self.model.load_state_dict(checkpoint)
        
        self.model.eval()
        print("âœ“ Model loaded\n")
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((512, 384)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ç”¨äºå­˜å‚¨ä¸­é—´ç‰¹å¾
        self.features = {}
        self._register_hooks()
    
    def _register_hooks(self):
        """æ³¨å†Œhookä»¥æå–ä¸­é—´ç‰¹å¾"""
        def get_activation(name):
            def hook(module, input, output):
                # å¦‚æœoutputæ˜¯å­—å…¸ï¼ˆSwin backboneçš„æƒ…å†µï¼‰
                if isinstance(output, dict) and 'hyper_in_feat_multi' in output:
                    feat0, feat1, feat2, feat3 = output['hyper_in_feat_multi']
                    self.features['stage0'] = feat0.detach()
                    self.features['stage1'] = feat1.detach()
                    self.features['stage2'] = feat2.detach()
                    self.features['stage3'] = feat3.detach()
                else:
                    self.features[name] = output.detach()
            return hook
        
        # æ³¨å†Œåˆ°Swin backbone
        self.model.swin.register_forward_hook(get_activation('swin'))
    
    def extract_features(self, img_path):
        """æå–ä¸€å¼ å›¾ç‰‡çš„4ä¸ªstageç‰¹å¾"""
        # è¯»å–å¹¶é¢„å¤„ç†å›¾ç‰‡
        img = Image.open(img_path).convert('RGB')
        img_original = np.array(img)
        
        img_tensor = self.transform(img).unsqueeze(0).to(self.device)
        
        # Forward pass
        with torch.no_grad():
            _ = self.model(img_tensor)
        
        # è¿”å›ç‰¹å¾å’ŒåŸå§‹å›¾ç‰‡
        return self.features, img_original


def visualize_feature_heatmaps(features, original_img, save_path):
    """
    å¯è§†åŒ–4ä¸ªstageçš„ç‰¹å¾çƒ­åŠ›å›¾
    
    Args:
        features: dict with keys 'stage0', 'stage1', 'stage2', 'stage3'
        original_img: åŸå§‹å›¾ç‰‡ (numpy array)
        save_path: ä¿å­˜è·¯å¾„
    """
    # è®¾ç½®å­—ä½“
    plt.rcParams['font.family'] = 'serif'
    plt.rcParams['font.serif'] = ['Times New Roman', 'Times', 'DejaVu Serif']
    plt.rcParams['font.size'] = 10
    
    # åˆ›å»ºå›¾è¡¨ - 3è¡Œ3åˆ—å¸ƒå±€
    fig = plt.figure(figsize=(12, 10))
    
    # é¡¶éƒ¨è·¨ä¸¤åˆ—: åŸå§‹å›¾ç‰‡
    ax_img = plt.subplot2grid((3, 3), (0, 0), colspan=2)
    ax_img.imshow(original_img)
    ax_img.set_title('Original Image with Distortion', fontsize=14, fontweight='bold')
    ax_img.axis('off')
    
    # å³ä¸Šè§’: å›¾ä¾‹è¯´æ˜
    ax_legend = plt.subplot2grid((3, 3), (0, 2))
    ax_legend.axis('off')
    ax_legend.text(0.1, 0.9, 'Feature Activation Heatmap', 
                   fontsize=11, fontweight='bold', transform=ax_legend.transAxes)
    ax_legend.text(0.1, 0.7, 'ğŸ”´ Red = High activation\n    (Model focuses here)', 
                   fontsize=9, transform=ax_legend.transAxes)
    ax_legend.text(0.1, 0.4, 'ğŸ”µ Blue = Low activation\n    (Less important)', 
                   fontsize=9, transform=ax_legend.transAxes)
    
    # 4ä¸ªstageçš„ç‰¹å¾å›¾
    stage_names = ['Stage 0\n(Low-level: 56Ã—56)', 
                   'Stage 1\n(Mid-level: 28Ã—28)', 
                   'Stage 2\n(High-level: 14Ã—14)', 
                   'Stage 3\n(Semantic: 7Ã—7)']
    
    positions = [
        (1, 0),  # Stage 0: ç¬¬2è¡Œç¬¬1åˆ—
        (1, 1),  # Stage 1: ç¬¬2è¡Œç¬¬2åˆ—
        (2, 0),  # Stage 2: ç¬¬3è¡Œç¬¬1åˆ—
        (2, 1),  # Stage 3: ç¬¬3è¡Œç¬¬2åˆ—
    ]
    
    # æå–å¹¶å¯è§†åŒ–æ¯ä¸ªstage
    for i, (stage_key, stage_name, pos) in enumerate(zip(
        ['stage0', 'stage1', 'stage2', 'stage3'], 
        stage_names, 
        positions
    )):
        if stage_key not in features:
            continue
        
        feat = features[stage_key]  # Shape: (1, C, H, W)
        
        # å¯¹æ‰€æœ‰é€šé“å–å¹³å‡ï¼Œå¾—åˆ°æ¿€æ´»å¼ºåº¦
        feat_mean = feat[0].mean(dim=0).cpu().numpy()  # (H, W)
        
        # å½’ä¸€åŒ–åˆ°0-1
        feat_min, feat_max = feat_mean.min(), feat_mean.max()
        if feat_max > feat_min:
            feat_norm = (feat_mean - feat_min) / (feat_max - feat_min)
        else:
            feat_norm = feat_mean
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        ax = plt.subplot2grid((3, 3), pos)
        im = ax.imshow(feat_norm, cmap='jet', interpolation='bilinear')
        
        # æ ‡é¢˜æ˜¾ç¤ºstageä¿¡æ¯
        ax.set_title(stage_name, fontsize=11, fontweight='bold')
        ax.axis('off')
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        cbar.set_label('Activation', fontsize=9)
    
    # å³ä¸‹è§’: ç»Ÿè®¡ä¿¡æ¯
    ax_stats = plt.subplot2grid((3, 3), (2, 2))
    ax_stats.axis('off')
    ax_stats.text(0.1, 0.9, 'Feature Statistics:', 
                  fontsize=10, fontweight='bold', transform=ax_stats.transAxes)
    
    for i, stage_key in enumerate(['stage0', 'stage1', 'stage2', 'stage3']):
        if stage_key not in features:
            continue
        feat = features[stage_key]
        channels = feat.shape[1]
        spatial = f"{feat.shape[2]}Ã—{feat.shape[3]}"
        ax_stats.text(0.1, 0.75 - i*0.15, 
                     f'S{i}: {channels}ch, {spatial}',
                     fontsize=8, transform=ax_stats.transAxes)
    
    plt.tight_layout()
    
    # ä¿å­˜
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved feature heatmap to: {save_path}")
    
    # ä¹Ÿä¿å­˜PNGç‰ˆæœ¬
    png_path = save_path.replace('.pdf', '.png')
    plt.savefig(png_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved PNG version to: {png_path}")
    
    plt.close()


def main():
    print("=" * 80)
    print("Feature Map Heatmap Visualization")
    print("=" * 80)
    
    # é…ç½®
    model_path = 'checkpoints/koniq-10k-swin_20251223_002226/best_model_srcc_0.9378_plcc_0.9485.pkl'
    
    if not os.path.exists(model_path):
        print(f"âŒ Model not found: {model_path}")
        return
    
    # ä½¿ç”¨æ³¨æ„åŠ›åˆ†æä¸­è¡¨ç°å¥½çš„å›¾ç‰‡ï¼ˆè´¨é‡å¯¹æ¯”æ˜æ˜¾ï¼‰
    # æ˜ç¡®é€‰æ‹©ï¼š1é«˜è´¨é‡ + 1ä¸­ä½è´¨é‡ + 1æä½è´¨é‡
    test_images = [
        ('koniq-10k/test/320987228.jpg', 'high_quality_MOS73'),      # é«˜è´¨é‡
        ('koniq-10k/train/5348237812.jpg', 'low_quality_MOS38'),     # ä½è´¨é‡  
        ('koniq-10k/train/5135908583.jpg', 'very_low_quality_MOS26'), # æä½è´¨é‡
    ]
    
    # æ£€æŸ¥æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨å°è¯•å¦ä¸€ä¸ªç›®å½•
    verified_images = []
    for path, label in test_images:
        if os.path.exists(path):
            verified_images.append((path, label))
        else:
            # å°è¯•å¦ä¸€ä¸ªç›®å½•
            alt_path = path.replace('/train/', '/test/') if '/train/' in path else path.replace('/test/', '/train/')
            if os.path.exists(alt_path):
                verified_images.append((alt_path, label))
    
    test_images = verified_images
    
    # åˆ›å»ºç‰¹å¾æå–å™¨
    extractor = FeatureExtractor(model_path)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'feature_visualizations'
    os.makedirs(output_dir, exist_ok=True)
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    for img_path, quality_label in test_images:
        if not os.path.exists(img_path):
            print(f"âš  Image not found: {img_path}")
            continue
        
        print(f"\n Processing: {os.path.basename(img_path)} ({quality_label})")
        
        # æå–ç‰¹å¾
        features, original_img = extractor.extract_features(img_path)
        
        # å¯è§†åŒ–
        save_path = os.path.join(output_dir, f'feature_heatmap_{quality_label}.pdf')
        visualize_feature_heatmaps(features, original_img, save_path)
    
    print("\n" + "=" * 80)
    print("âœ… Feature visualization completed!")
    print("=" * 80)
    print(f"\nGenerated files in: {output_dir}/")
    print("  - feature_heatmap_*.pdf (for paper)")
    print("  - feature_heatmap_*.png (preview)")


if __name__ == '__main__':
    main()

