%%% ===============================================================================
%%% SMART-IQA Reference Database
%%% ===============================================================================
%%% Usage:
%%% 1. Add BibTeX entries to this file
%%% 2. Cite in text using \cite{key}
%%% 3. Compile: pdflatex -> bibtex -> pdflatex -> pdflatex
%%% ===============================================================================

%%% ===============================================================================
%%% Core IQA Papers
%%% ===============================================================================

@inproceedings{su2020hyperiq,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3667--3676},
  year={2020}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

%%% ===============================================================================
%%% IQA Datasets
%%% ===============================================================================

@article{hosu2020koniq,
  title={KonIQ-10k: An ecologically valid database for deep learning of blind image quality assessment},
  author={Hosu, Vlad and Lin, Hanhe and Sziranyi, Tamas and Saupe, Dietmar},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4041--4056},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fang2020perceptual,
  title={Perceptual quality assessment of smartphone photography},
  author={Fang, Yuming and Zhu, Hanwei and Zeng, Yan and Ma, Kede and Wang, Zhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3677--3686},
  year={2020}
}

@inproceedings{lin2019kadid,
  title={KADID-10k: A large-scale artificially distorted IQA database},
  author={Lin, Hanhe and Hosu, Vlad and Saupe, Dietmar},
  booktitle={2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)},
  pages={1--3},
  year={2019},
  organization={IEEE}
}

@article{li2023agiqa,
  title={AGIQA-3K: An open database for AI-generated image quality assessment},
  author={Li, Chunyi and Zhang, Zicheng and Wu, Haoning and Sun, Wei and Min, Xiongkuo and Liu, Xiaohong and Zhai, Guangtao and Lin, Weisi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}

%%% ===============================================================================
%%% SOTA IQA Methods
%%% ===============================================================================

@article{talebi2018nima,
  title={NIMA: Neural image assessment},
  author={Talebi, Hossein and Milanfar, Peyman},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={8},
  pages={3998--4011},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ying2020paq2piq,
  title={From patches to pictures (PaQ-2-PiQ): Mapping the perceptual space of picture quality},
  author={Ying, Zhenqiang and Niu, Haoran and Gupta, Praful and Mahajan, Dhruv and Ghadiyaram, Deepti and Bovik, Alan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3575--3585},
  year={2020}
}

@inproceedings{ke2021musiq,
  title={MUSIQ: Multi-scale image quality transformer},
  author={Ke, Junjie and Wang, Qifei and Wang, Yilin and Milanfar, Peyman and Yang, Feng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5148--5157},
  year={2021}
}

@inproceedings{golestaneh2022tres,
  title={No-reference image quality assessment via transformers, relative ranking, and self-consistency},
  author={Golestaneh, S Alireza and Dadsetan, Saba and Kitani, Kris M},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1220--1230},
  year={2022}
}

@inproceedings{yang2022maniqa,
  title={MANIQA: Multi-dimension attention network for no-reference image quality assessment},
  author={Yang, Sidi and Wu, Tianhe and Shi, Shuwei and Lao, Shanshan and Gong, Yuan and Cao, Mingdeng and Wang, Jiahao and Yang, Yujiu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={1191--1200},
  year={2022}
}

@inproceedings{zhang2023liqe,
  title={Blind image quality assessment via vision-language correspondence: A multitask learning perspective},
  author={Zhang, Weixia and Zhai, Guangtao and Wei, Ying and Yang, Xiaokang and Ma, Kede},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14071--14081},
  year={2023}
}

@article{wu2023qalign,
  title={Q-Align: Teaching LMMs for visual scoring via discrete text-defined levels},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Weixia and Chen, Chaofeng and Li, Chunyi and Liao, Liang and Wang, Annan and Zhang, Erli and Sun, Wenxiu and Yan, Qiong and others},
  journal={arXiv preprint arXiv:2312.17090},
  year={2023}
}

%%% ===============================================================================
%%% Transformer Architectures
%%% ===============================================================================

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{dosovitskiy2021vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

%%% ===============================================================================
%%% Attention Mechanisms
%%% ===============================================================================

@inproceedings{hu2018senet,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{woo2018cbam,
  title={CBAM: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

%%% ===============================================================================
%%% Loss Functions
%%% ===============================================================================

@inproceedings{liu2017ranknet,
  title={From rankings to ratings: Learning personal preferences from pairwise comparisons},
  author={Liu, Xiaoming and Lu, Chao-Tung and Wang, Pin and Chen, Tsuhan},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={655--663},
  year={2017}
}

@article{zhang2018dbcnn,
  title={Blind image quality assessment using a deep bilinear convolutional neural network},
  author={Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={1},
  pages={36--47},
  year={2018},
  publisher={IEEE}
}

@inproceedings{zhang2021unique,
  title={Uncertainty-aware blind image quality assessment in the laboratory and wild},
  author={Zhang, Weixia and Ma, Kede and Zhai, Guangtao and Yang, Xiaokang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3142--3151},
  year={2021}
}

@article{sun2024stairiqa,
  title={StairIQA: Towards staircase-shaped quality scales for blind image quality assessment},
  author={Sun, Wei and Zhang, Haoning and Liao, Liang and Wei, Ying and Zhai, Guangtao and Min, Xiongkuo},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

%%% ===============================================================================
%%% ADD YOUR NEW REFERENCES BELOW THIS LINE
%%% ===============================================================================

