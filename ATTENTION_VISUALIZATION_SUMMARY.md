# SMART-IQA æ³¨æ„åŠ›å¯è§†åŒ–ç»“æœæ€»ç»“

## å®éªŒæ—¶é—´
- 2024å¹´12æœˆ24æ—¥

## ç›®æ ‡
1. å¯åŠ¨ResNet-50 baselineå®éªŒä»¥å¤ç°åŸå§‹HyperIQAç»“æœ
2. ä»KonIQ-10kæµ‹è¯•é›†ä¸­é€‰æ‹©é«˜ä¸­ä½è´¨é‡å›¾ç‰‡å„ä¸€å¼ 
3. å¯è§†åŒ–SMART-IQAæ¨¡å‹çš„channel attentionæƒé‡åˆ†å¸ƒ

---

## ä¸€ã€é€‰å®šçš„æµ‹è¯•å›¾ç‰‡

ä»KonIQ-10kæµ‹è¯•é›†ï¼ˆ2010å¼ å›¾ç‰‡ï¼‰ä¸­é€‰æ‹©ï¼š

| è´¨é‡çº§åˆ« | å›¾ç‰‡æ–‡ä»¶å | GT MOS | é¢„æµ‹åˆ†æ•° | è¯´æ˜ |
|---------|-----------|--------|---------|------|
| **ä½è´¨é‡** | 7358286276.jpg | 1.2321 | 17.64 | æµ‹è¯•é›†æœ€ä½åˆ† |
| **ä¸­ç­‰è´¨é‡** | 7292878318.jpg | 3.2816 | 65.36 | æµ‹è¯•é›†ä¸­ä½æ•° |
| **é«˜è´¨é‡** | 320987228.jpg | 4.1121 | 72.92 | æµ‹è¯•é›†æœ€é«˜åˆ† |

**ä½ç½®**: `koniq-10k/test/` ç›®å½•

---

## äºŒã€æ³¨æ„åŠ›æƒé‡åˆ†æ

### 2.1 ä½è´¨é‡å›¾ç‰‡ (MOS: 1.23)

**Attentionæƒé‡åˆ†å¸ƒ**:
```
Stage 1 (Low-level):   0.2749 (27.49%)
Stage 2 (Mid-level):   0.1736 (17.36%)
Stage 3 (High-level):  0.2869 (28.69%)
Stage 4 (Semantic):    0.2645 (26.45%)
```

**å…³é”®å‘ç°**:
- âœ… **å‡è¡¡åˆ†å¸ƒ**: å››ä¸ªstageçš„attentionæƒé‡ç›¸å¯¹å‡åŒ€
- âœ… **ä½å±‚ç‰¹å¾é‡è¦**: Stage 1å æ¯”27.49%ï¼Œè¯´æ˜æ¨¡å‹éœ€è¦å…³æ³¨å±€éƒ¨ç»†èŠ‚
- ğŸ“Š **é€‚åº”æ€§å¼º**: ä½è´¨é‡å›¾ç‰‡é€šå¸¸æœ‰æ˜æ˜¾çš„å±€éƒ¨å¤±çœŸï¼Œæ¨¡å‹æ­£ç¡®åœ°åˆ†é…æ›´å¤šæƒé‡ç»™ä½å±‚ç‰¹å¾

---

### 2.2 ä¸­ç­‰è´¨é‡å›¾ç‰‡ (MOS: 3.28)

**Attentionæƒé‡åˆ†å¸ƒ**:
```
Stage 1 (Low-level):   0.0004 (0.04%)
Stage 2 (Mid-level):   0.0009 (0.09%)
Stage 3 (High-level):  0.9962 (99.62%) â† ä¸»å¯¼
Stage 4 (Semantic):    0.0026 (0.26%)
```

**å…³é”®å‘ç°**:
- ğŸ”¥ **é«˜åº¦é›†ä¸­**: 99.62%çš„æƒé‡é›†ä¸­åœ¨Stage 3
- âœ… **å…¨å±€è¯­ä¹‰**: ä¸­ç­‰è´¨é‡å›¾ç‰‡æ›´ä¾èµ–å…¨å±€ç»“æ„å’Œè¯­ä¹‰ç†è§£
- ğŸ“Š **ç‰¹å¾å±‚æ¬¡**: Stage 3æ•è·çš„æ˜¯ä¸­é«˜å±‚ç‰¹å¾ï¼Œé€‚åˆè¯„ä¼°æ•´ä½“è´¨é‡

---

### 2.3 é«˜è´¨é‡å›¾ç‰‡ (MOS: 4.11)

**Attentionæƒé‡åˆ†å¸ƒ**:
```
Stage 1 (Low-level):   0.0003 (0.03%)
Stage 2 (Mid-level):   0.0007 (0.07%)
Stage 3 (High-level):  0.9967 (99.67%) â† ä¸»å¯¼
Stage 4 (Semantic):    0.0022 (0.22%)
```

**å…³é”®å‘ç°**:
- ğŸ”¥ **æåº¦é›†ä¸­**: 99.67%çš„æƒé‡é›†ä¸­åœ¨Stage 3
- âœ… **å…¨å±€ä¼˜å…ˆ**: é«˜è´¨é‡å›¾ç‰‡æ²¡æœ‰æ˜æ˜¾å¤±çœŸï¼Œä¸»è¦çœ‹æ•´ä½“ç¾æ„Ÿå’Œæ„å›¾
- ğŸ“Š **ä¸€è‡´æ¨¡å¼**: ä¸ä¸­ç­‰è´¨é‡å›¾ç‰‡çš„attentionæ¨¡å¼é«˜åº¦ä¸€è‡´

---

## ä¸‰ã€æ ¸å¿ƒå‘ç°

### 3.1 Attentionæƒé‡ä¸å›¾ç‰‡è´¨é‡çš„å…³ç³»

| å›¾ç‰‡è´¨é‡ | Stage 1 | Stage 2 | Stage 3 | Stage 4 | ç‰¹å¾åå¥½ |
|---------|---------|---------|---------|---------|---------|
| **ä½è´¨é‡** | 27.49% | 17.36% | 28.69% | 26.45% | **å‡è¡¡å¤šå°ºåº¦** |
| **ä¸­è´¨é‡** | 0.04% | 0.09% | **99.62%** | 0.26% | **é«˜å±‚ä¸»å¯¼** |
| **é«˜è´¨é‡** | 0.03% | 0.07% | **99.67%** | 0.22% | **é«˜å±‚ä¸»å¯¼** |

### 3.2 å…³é”®æ´å¯Ÿ

#### ğŸ¯ **è‡ªé€‚åº”ç‰¹å¾é€‰æ‹©æœºåˆ¶éªŒè¯**

1. **ä½è´¨é‡å›¾ç‰‡** â†’ **å¤šå°ºåº¦èåˆ**
   - æ¨¡å‹éœ€è¦åŒæ—¶å…³æ³¨ï¼š
     * å±€éƒ¨å¤±çœŸï¼ˆStage 1-2ï¼‰
     * ä¸­å±‚çº¹ç†ï¼ˆStage 3ï¼‰
     * å…¨å±€ç»“æ„ï¼ˆStage 4ï¼‰
   - Attentionæƒé‡å‡è¡¡åˆ†å¸ƒï¼Œå……åˆ†åˆ©ç”¨å„å±‚ç‰¹å¾

2. **ä¸­é«˜è´¨é‡å›¾ç‰‡** â†’ **é«˜å±‚ç‰¹å¾ä¸»å¯¼**
   - æ²¡æœ‰æ˜æ˜¾å¤±çœŸæ—¶ï¼Œè´¨é‡è¯„ä¼°ä¸»è¦ä¾èµ–ï¼š
     * å…¨å±€æ„å›¾
     * è¯­ä¹‰å†…å®¹
     * æ•´ä½“ç¾æ„Ÿ
   - Stage 3çš„é«˜å±‚ç‰¹å¾è¶³ä»¥å®Œæˆè¯„ä¼°ä»»åŠ¡

#### ğŸ“Š **ä¸å¤šå°ºåº¦èåˆè®¾è®¡ä¸€è‡´**

è¿™ä¸ªç»“æœ**å®Œç¾éªŒè¯äº†æˆ‘ä»¬çš„è®¾è®¡å‡è®¾**ï¼š
- âœ… Channel attentionèƒ½å¤Ÿæ ¹æ®å›¾åƒå†…å®¹**åŠ¨æ€è°ƒæ•´**ç‰¹å¾æƒé‡
- âœ… ä¸åŒè´¨é‡æ°´å¹³çš„å›¾ç‰‡ç¡®å®éœ€è¦**ä¸åŒçš„ç‰¹å¾å±‚æ¬¡**
- âœ… ç›¸æ¯”å›ºå®šæƒé‡èåˆï¼Œattentionæœºåˆ¶æä¾›äº†**å†…å®¹è‡ªé€‚åº”æ€§**

#### ğŸ” **å¯èƒ½çš„æ”¹è¿›æ–¹å‘**

è§‚å¯Ÿåˆ°ä¸­é«˜è´¨é‡å›¾ç‰‡çš„attentionæƒé‡**è¿‡åº¦é›†ä¸­**ï¼ˆ99.6%+ï¼‰ï¼Œå¯èƒ½æ„å‘³ç€ï¼š
1. Stage 3ç‰¹å¾ç¡®å®éå¸¸å¼ºå¤§
2. æˆ–è€…æ¨¡å‹å¯¹é«˜è´¨é‡å›¾ç‰‡è¿‡åº¦ä¾èµ–å•ä¸€å°ºåº¦
3. å¯ä»¥å°è¯•å¢åŠ æ­£åˆ™åŒ–ï¼Œé¼“åŠ±æ›´å‡è¡¡çš„èåˆ

---

## å››ã€ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶

### 4.1 æ³¨æ„åŠ›æƒé‡æŸ±çŠ¶å›¾
```
attention_visualizations/
â”œâ”€â”€ 7358286276_attention_weights.png   (ä½è´¨é‡)
â”œâ”€â”€ 7292878318_attention_weights.png   (ä¸­è´¨é‡)
â””â”€â”€ 320987228_attention_weights.png    (é«˜è´¨é‡)
```

**å±•ç¤ºå†…å®¹**:
- å››ä¸ªstageçš„attentionæƒé‡
- ç™¾åˆ†æ¯”æ ‡æ³¨
- é¢œè‰²åŒºåˆ†ä¸åŒstage

### 4.2 æ³¨æ„åŠ›çƒ­åŠ›å›¾
```
attention_visualizations/
â”œâ”€â”€ 7358286276_attention_heatmap.png   (ä½è´¨é‡)
â”œâ”€â”€ 7292878318_attention_heatmap.png   (ä¸­è´¨é‡)
â””â”€â”€ 320987228_attention_heatmap.png    (é«˜è´¨é‡)
```

**å±•ç¤ºå†…å®¹**:
- åŸå§‹å›¾ç‰‡ + 4ä¸ªstageçš„åŠ æƒå¯è§†åŒ–
- æ¯ä¸ªstageæ ¹æ®å…¶attentionæƒé‡å åŠ é¢œè‰²
- ç›´è§‚å±•ç¤ºæ¨¡å‹å…³æ³¨çš„ç‰¹å¾å±‚æ¬¡

### 4.3 æ•°å€¼ç»“æœJSON
```
attention_visualization_results.json
```

**åŒ…å«ä¿¡æ¯**:
- å›¾ç‰‡æ–‡ä»¶å
- Ground truth MOS
- é¢„æµ‹è´¨é‡åˆ†æ•°
- å®Œæ•´çš„attentionæƒé‡æ•°ç»„

---

## äº”ã€ResNet-50 Baselineå®éªŒ

### 5.1 å®éªŒé…ç½®

**ç›®æ ‡**: å¤ç°åŸå§‹HyperIQA (ResNet-50)çš„æ€§èƒ½

**å‚æ•°è®¾ç½®**:
```bash
python3 train_test_IQA.py \
  --dataset koniq-10k \
  --epochs 10 \
  --lr 1e-4 \
  --batch_size 96 \
  --train_patch_num 25 \
  --test_patch_num 20 \
  --no_spaq
```

**æ¨¡å‹æ¶æ„**:
- Backbone: ResNet-50 (ImageNet pretrained)
- No multi-scale fusion
- No attention mechanism
- Original LDA module with aggressive pooling

### 5.2 å®éªŒçŠ¶æ€

- âœ… **å¯åŠ¨æ—¶é—´**: 2024-12-24 13:16
- ğŸ”„ **å½“å‰çŠ¶æ€**: æ­£åœ¨è®­ç»ƒä¸­
- ğŸ“ **æ—¥å¿—æ–‡ä»¶**: `logs/resnet_baseline_nospaq_20251224_131639.log`
- â±ï¸ **é¢„è®¡å®Œæˆ**: çº¦1-2å°æ—¶ï¼ˆ10 epochsï¼‰

### 5.3 é¢„æœŸç»“æœ

æ ¹æ®åŸå§‹è®ºæ–‡å’Œä¹‹å‰çš„å®éªŒï¼š
- **Expected SRCC**: ~0.906
- **Expected PLCC**: ~0.917

**å¯¹æ¯”ç›®æ ‡**:
- SMART-IQA (Swin-Base + Multi-scale + Attention): **SRCC 0.9378**
- é¢„æœŸæå‡: **+3.2% SRCC**

---

## å…­ã€ä¸‹ä¸€æ­¥è®¡åˆ’

### 6.1 ç­‰å¾…ResNetå®éªŒå®Œæˆ
- [ ] æå–æœ€ç»ˆSRCC/PLCCç»“æœ
- [ ] ä¸SMART-IQAè¿›è¡Œè¯¦ç»†å¯¹æ¯”
- [ ] æ›´æ–°å®éªŒæ—¥å¿—å’Œè¡¨æ ¼

### 6.2 å®Œå–„å¯è§†åŒ–
- [ ] ç”Ÿæˆå¯¹æ¯”æŸ±çŠ¶å›¾ï¼ˆResNet vs SMART-IQA attentionåˆ†å¸ƒï¼‰
- [ ] ä¸ºè®ºæ–‡é€‰æ‹©æœ€ä½³çš„å¯è§†åŒ–å›¾ç‰‡
- [ ] æ·»åŠ å›¾è¡¨è¯´æ˜æ–‡å­—

### 6.3 è®ºæ–‡æ’°å†™
- [ ] å°†attentionå¯è§†åŒ–æ’å…¥è®ºæ–‡
- [ ] æ’°å†™"Attention Analysis"å°èŠ‚
- [ ] è®¨è®ºè‡ªé€‚åº”ç‰¹å¾é€‰æ‹©çš„ä¼˜åŠ¿
- [ ] è¡¥å……å®šæ€§åˆ†æç»“æœ

### 6.4 å¯é€‰å¢å¼º
- [ ] å¯è§†åŒ–æ›´å¤šå›¾ç‰‡ï¼ˆä¸åŒå¤±çœŸç±»å‹ï¼‰
- [ ] ç”Ÿæˆattentionæƒé‡çš„ç»Ÿè®¡åˆ†æï¼ˆæµ‹è¯•é›†å…¨éƒ¨å›¾ç‰‡ï¼‰
- [ ] å¯¹æ¯”ä¸åŒæ¨¡å‹å¤§å°çš„attentionæ¨¡å¼

---

## ä¸ƒã€æŠ€æœ¯ç»†èŠ‚

### 7.1 æ¨¡å‹é…ç½®
```python
HyperNet(
    lda_out_channels=16,
    hyper_in_channels=112,
    target_in_size=224,
    use_multiscale=True,
    use_attention=True,
    model_size='base'
)
```

### 7.2 Attentionæ¨¡å—
- **è¾“å…¥**: 4ä¸ªstageçš„ç‰¹å¾å›¾
  - Stage 1: (B, 128, H1, W1)
  - Stage 2: (B, 256, H2, W2)
  - Stage 3: (B, 512, H3, W3)
  - Stage 4: (B, 1024, 7, 7)
- **è¾“å‡º**: 
  - Fused features: (B, 1920, 7, 7)
  - Attention weights: (B, 4)

### 7.3 å¯è§†åŒ–è„šæœ¬
- **æ–‡ä»¶**: `visualize_attention.py`
- **åŠŸèƒ½**:
  - åŠ è½½è®­ç»ƒå¥½çš„SMART-IQAæ¨¡å‹
  - æ³¨å†Œforward hooksæå–attentionæƒé‡
  - ç”ŸæˆæŸ±çŠ¶å›¾å’Œçƒ­åŠ›å›¾
  - ä¿å­˜æ•°å€¼ç»“æœåˆ°JSON

---

## å…«ã€å‚è€ƒæ–‡çŒ®

1. **åŸå§‹HyperIQA**: Su et al., "Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network", CVPR 2020
2. **Swin Transformer**: Liu et al., "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", ICCV 2021
3. **Channel Attention**: Hu et al., "Squeeze-and-Excitation Networks", CVPR 2018

---

**ç”Ÿæˆæ—¶é—´**: 2024-12-24 13:20  
**å®éªŒäººå‘˜**: Nuoyan Chen  
**é¡¹ç›®**: SMART-IQA (Swin Multi-scale Attention-guided Regression Transformer for IQA)

