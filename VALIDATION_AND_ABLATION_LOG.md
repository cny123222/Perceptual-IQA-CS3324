# Validation and Ablation Experiments Log

**Purpose**: Track all validation, cross-dataset testing, and ablation experiments

**Best Model Baseline**:
- Configuration: Swin-Base + Attention + Ranking Loss (alpha=0.5)
- Performance: SRCC 0.9343, PLCC 0.9463
- Checkpoint: `checkpoints/koniq-10k-swin-ranking-alpha0.5_20251221_155013/best_model_srcc_0.9343_plcc_0.9463.pkl`

---

## üìä Cross-Dataset Testing Results

| Dataset | Domain | # Images | SRCC | PLCC | Status | Log File | Notes |
|---------|--------|----------|------|------|--------|----------|-------|
| **KonIQ-10k Test** | In-domain | 2,010 | 0.9343 | 0.9463 | ‚úÖ Done | `logs/swin_multiscale_ranking_alpha0.5_20251221_155013.log` | Training test set |
| **SPAQ** | Cross-domain | ? | ? | ? | ‚è≥ Running | `logs/cross_dataset_test_base_20251221_193204.log` | Smartphone photos |
| **KADID-10K** | Cross-domain | ? | ? | ? | ‚è≥ Running | `logs/cross_dataset_test_base_20251221_193204.log` | Synthetic distortions |
| **AGIQA-3K** | Cross-domain | ? | ? | ? | ‚è≥ Running | `logs/cross_dataset_test_base_20251221_193204.log` | AI-generated images |

**Started**: Dec 21, 2025 19:32  
**Estimated Completion**: ~60 minutes from start

---

## üî¨ Ablation Study Results

**Methodology**: Subtractive approach - remove one component from the full model

### Main Results Table

| Experiment | Configuration | SRCC | PLCC | SRCC Œî | PLCC Œî | Status | Log File | Training Time |
|------------|---------------|------|------|--------|--------|--------|----------|---------------|
| **Full Model** | Base + Att + Rank(0.5) + Strong Reg | **0.9343** | **0.9463** | - | - | ‚úÖ Done | `logs/swin_multiscale_ranking_alpha0.5_20251221_155013.log` | 10 epochs |
| **Remove Attention** | Base + Rank(0.5) + Strong Reg | 0.9336 | 0.9464 | -0.0007 | +0.0001 | ‚úÖ Done | `logs/swin_multiscale_ranking_alpha0.5_20251221_003537.log` | 30 epochs |
| **Remove Ranking Loss** | Base + Att + L1 Only + Strong Reg | ? | ? | ? | ? | ‚è∞ Pending | - | ~10 hours |
| **Weak Regularization** | Base + Att + Rank(0.5) + Weak Reg | ? | ? | ? | ? | ‚è∞ Pending | - | ~10 hours |

### Component Contribution Analysis

| Component | Contribution (SRCC) | Contribution (PLCC) | Importance |
|-----------|---------------------|---------------------|------------|
| **Attention Fusion** | +0.0007 | -0.0001 | Low but positive |
| **Ranking Loss (Œ±=0.5)** | ? | ? | TBD |
| **Strong Regularization** | ? | ? | TBD |

---

## üîß Ablation Experiment Details

### Experiment 1: Remove Ranking Loss ‚è∞ Pending

**Configuration**:
```bash
python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 30 \
  --patience 7 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --ranking_loss_alpha 0 \
  --use_attention \
  --lr 5e-6 \
  --weight_decay 2e-4 \
  --drop_path_rate 0.3 \
  --dropout_rate 0.4 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

**Purpose**: Quantify the contribution of ranking loss

**Expected Results**: Lower SRCC (based on previous experiments showing ranking loss helps)

**Status**: Not started

---

### Experiment 2: Weak Regularization ‚è∞ Pending

**Configuration**:
```bash
python train_swin.py \
  --dataset koniq-10k \
  --model_size base \
  --batch_size 32 \
  --epochs 30 \
  --patience 7 \
  --train_patch_num 20 \
  --test_patch_num 20 \
  --ranking_loss_alpha 0.5 \
  --use_attention \
  --lr 5e-6 \
  --weight_decay 1e-4 \
  --drop_path_rate 0.2 \
  --dropout_rate 0.3 \
  --lr_scheduler cosine \
  --test_random_crop \
  --no_spaq
```

**Changes from Full Model**:
- `weight_decay`: 2e-4 ‚Üí 1e-4 (50% reduction)
- `drop_path_rate`: 0.3 ‚Üí 0.2 (33% reduction)
- `dropout_rate`: 0.4 ‚Üí 0.3 (25% reduction)

**Purpose**: Demonstrate the importance of strong regularization for large models

**Expected Results**: Overfitting, lower test SRCC

**Status**: Not started

---

## üìà Complexity Analysis Results

| Metric | Value | Status | Notes |
|--------|-------|--------|-------|
| **Parameters** | 88.85M | ‚úÖ Known | From model architecture |
| **FLOPs (ptflops)** | ~17.77 GFLOPs | ‚è∞ To measure | Estimated |
| **FLOPs (thop)** | ? | ‚è∞ To measure | Cross-validation |
| **Inference Time (mean)** | ~17.27 ms | ‚è∞ To measure | Estimated |
| **Inference Time (std)** | ~6.58 ms | ‚è∞ To measure | Estimated |
| **Throughput (batch=1)** | ~58 img/s | ‚è∞ To measure | Estimated |
| **Throughput (batch=4)** | ? | ‚è∞ To measure | - |
| **Throughput (batch=8)** | ? | ‚è∞ To measure | - |

**Command to Run**:
```bash
cd /root/Perceptual-IQA-CS3324/complexity
python compute_complexity.py --model_size base --use_attention --input_size 384 384
```

**Status**: Not started  
**Estimated Time**: 30 minutes

---

## üéØ Experiment Priority Queue

| Priority | Task | Estimated Time | Status |
|----------|------|----------------|--------|
| 1 | Cross-Dataset Testing | 60 min | ‚è≥ Running |
| 2 | Complexity Analysis | 30 min | ‚è∞ Next |
| 3 | Ablation: Remove Ranking Loss | 10-12 hours | ‚è∞ Pending |
| 4 | Ablation: Weak Regularization | 10-12 hours | ‚è∞ Pending |
| 5 | Results Organization | 2-3 hours | ‚è∞ Pending |
| 6 | Paper Writing | 2-3 days | ‚è∞ Pending |

---

## üìù Notes and Observations

### Dec 21, 2025

**19:32** - Started cross-dataset testing for best model (Base + Attention, SRCC 0.9343)
- Testing on KonIQ, SPAQ, KADID-10K, AGIQA-3K
- Log: `logs/cross_dataset_test_base_20251221_193204.log`
- Estimated completion: ~20:30

**Key Findings So Far**:
1. ‚úÖ Attention fusion provides +0.07% SRCC improvement on Base model
2. ‚úÖ Alpha=0.5 is optimal for ranking loss (alpha=0.3 performs worse)
3. ‚úÖ Strong regularization is critical for Base model
4. ‚úÖ Model training is stable and reproducible with seed=42

---

## üîÑ Update History

| Date | Updates |
|------|---------|
| Dec 21, 2025 19:40 | Created log file, started cross-dataset testing |

---

**Instructions for Updating**:
1. After each experiment completes, fill in the results in the tables above
2. Add observations and notes in the Notes section
3. Update priority queue as tasks are completed
4. Keep this file as the single source of truth for all validation experiments

