# Ranking Loss 超参数调优指南

## 参数说明

### 1. `alpha` (权重参数) - **更重要**

**作用**：控制 ranking loss 相对于 L1 loss 的权重
- 公式：`total_loss = L1_loss + alpha * ranking_loss`
- 影响范围：直接决定 ranking loss 对训练的贡献

**重要性**：⭐⭐⭐⭐⭐ (非常重要)
- 这是影响模型性能最关键的参数
- 过小：ranking loss 贡献不足，效果不明显
- 过大：可能压制 L1 loss，导致数值不稳定或过拟合

**典型值范围**：`[0.1, 0.5, 1.0, 2.0]`
- `0.1-0.3`：保守，轻微优化排序
- `0.5`：平衡（默认值，建议从这开始）
- `1.0-2.0`：激进，强烈优化排序，但可能影响绝对值预测

### 2. `margin` (边界参数) - 相对次要

**作用**：Hinge loss 的边界值，决定预测差异多大时才算排序错误
- 公式：`loss = max(0, -pred_diff * label_sign + margin)`
- 影响范围：影响 ranking loss 的敏感度

**重要性**：⭐⭐⭐ (中等重要)
- 通常变化范围较小，影响不如 alpha 明显
- 主要影响对"轻微排序错误"的惩罚程度

**典型值范围**：`[0.05, 0.1, 0.2]`
- `0.05`：非常敏感，对微小排序错误也惩罚
- `0.1`：默认值，平衡敏感度（建议从这开始）
- `0.2`：较宽松，只惩罚明显的排序错误

## 调优策略

### 推荐策略：先调 alpha，再微调 margin

#### 阶段 1：固定 margin，测试 alpha
1. **设置** `margin=0.1`（默认值）
2. **测试** `alpha` 值：`[0.1, 0.5, 1.0, 2.0]`
3. **选择** 测试集 SRCC 最高的 `alpha` 值

#### 阶段 2：固定最优 alpha，微调 margin
1. **使用** 阶段 1 找到的最优 `alpha`
2. **测试** `margin` 值：`[0.05, 0.1, 0.15, 0.2]`
3. **选择** 测试集 SRCC 最高的 `margin` 值（通常差异很小）

### 快速测试方案（节省时间）

如果训练时间有限，可以采用以下策略：

#### 方案 A：粗粒度测试（推荐）
```
测试组合：
1. alpha=0.5, margin=0.1  (默认)
2. alpha=1.0, margin=0.1  (2倍权重)
3. alpha=0.3, margin=0.1  (降低权重)
4. alpha=0.5, margin=0.15 (微调margin)

选择最佳组合
```

#### 方案 B：只测试 alpha（最快）
```
只测试 alpha 值：0.3, 0.5, 1.0
固定 margin=0.1
```

## 参数对比

| 参数 | 重要性 | 影响范围 | 推荐调优顺序 | 典型变化幅度 |
|------|--------|----------|--------------|--------------|
| **alpha** | ⭐⭐⭐⭐⭐ | 大 | **先调** | 0.1 → 2.0 (20倍) |
| **margin** | ⭐⭐⭐ | 小 | 后调 | 0.05 → 0.2 (4倍) |

## 预期效果

### Alpha 对性能的影响

根据经验（基于其他 IQA 论文）：
- **alpha = 0** (纯 L1)：基线性能
- **alpha = 0.1-0.3**：SRCC 可能提升 0.001-0.003
- **alpha = 0.5-1.0**：SRCC 可能提升 0.003-0.008（**最佳范围**）
- **alpha > 2.0**：可能不稳定，SRCC 反而下降

### Margin 对性能的影响

通常影响较小：
- **margin = 0.05-0.15**：性能差异通常 < 0.002
- 只在 alpha 确定后再微调

## 实用建议

### 1. **是否需要多次测试？**

**是的，但要有策略**：
- ✅ **必须测试 alpha**：这是最重要的参数，不同值可能带来 0.003-0.008 的 SRCC 提升
- ⚠️ **可选测试 margin**：通常影响较小（< 0.002），如果时间有限可以跳过

### 2. **哪个参数更重要？**

**Alpha 更重要**（优先级 5:3）
- Alpha 影响是 margin 的 3-5 倍
- 建议将 80% 的调优时间花在 alpha 上

### 3. **如何高效调优？**

**最小化测试方案**（3-4 次训练）：
```bash
# 1. 基线（无 ranking loss）
python train_swin.py --ranking_loss_alpha 0 ...

# 2. 测试 alpha=0.5 (默认)
python train_swin.py --ranking_loss_alpha 0.5 --ranking_loss_margin 0.1 ...

# 3. 如果 alpha=0.5 效果好，测试 alpha=1.0
python train_swin.py --ranking_loss_alpha 1.0 --ranking_loss_margin 0.1 ...

# 4. (可选) 如果 alpha=1.0 最好，微调 margin
python train_swin.py --ranking_loss_alpha 1.0 --ranking_loss_margin 0.15 ...
```

**完整测试方案**（8-10 次训练）：
- Alpha: [0.1, 0.3, 0.5, 1.0, 2.0] × Margin: [0.1]
- 然后对最佳 alpha，测试 margin: [0.05, 0.15, 0.2]

### 4. **快速判断标准**

训练过程中观察：
- **Ranking loss 值**：应该在 0.01-0.1 范围内（如果太大，alpha 可能过高）
- **L1 loss vs Ranking loss 比例**：理想情况下 ranking loss 大约是 L1 loss 的 10-30%
- **测试 SRCC 提升**：如果提升 < 0.001，可能 alpha 太小；如果下降，可能 alpha 太大

## 总结

1. **Alpha 更重要**：优先调优 alpha，将大部分时间花在这上面
2. **Margin 次要**：在 alpha 确定后，可以快速测试几个值或直接使用默认值
3. **建议流程**：
   - 第一次：alpha=0.5, margin=0.1（默认）
   - 如果效果好：测试 alpha=[0.3, 1.0]
   - 如果时间充足：再微调 margin

4. **预期收益**：
   - 正确调优 alpha 可能带来 0.003-0.008 的 SRCC 提升
   - 调优 margin 可能带来 0.001-0.002 的额外提升

