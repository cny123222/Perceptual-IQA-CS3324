#!/usr/bin/env python3
"""
ResNet50-based HyperIQA å¤æ‚åº¦åˆ†æ
"""

import torch
import torch.nn as nn
import time
import numpy as np
from PIL import Image
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from smart_iqa.models import hyperiqa as models  # åŸå§‹çš„ResNet-based HyperIQA
from torchvision import transforms

def analyze_resnet_complexity():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    # åˆ›å»ºResNet50-based HyperIQAæ¨¡å‹
    print("\nCreating ResNet50-based HyperIQA model...")
    model = models.HyperNet(16, 112, 224, 112, 56, 28, 14, 7).to(device)
    model.eval()
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"Total parameters: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"Trainable parameters: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    
    # å°è¯•è®¡ç®—FLOPs
    flops_str = "N/A"
    try:
        from ptflops import get_model_complexity_info
        input_size = (3, 224, 224)
        macs, params = get_model_complexity_info(
            model, input_size, 
            as_strings=False,
            print_per_layer_stat=False,
            verbose=False
        )
        flops_str = f"{macs / 1e9:.2f} GFLOPs"
        print(f"FLOPs: {flops_str}")
    except ImportError:
        print("âš ï¸  ptflops not installed, skipping FLOPs calculation")
    
    # æµ‹è¯•æ¨ç†æ—¶é—´
    print("\nMeasuring inference time...")
    input_tensor = torch.randn(1, 3, 224, 224).to(device)
    
    # Warmup
    for _ in range(10):
        with torch.no_grad():
            _ = model(input_tensor)
    
    # å®é™…æµ‹é‡
    times = []
    num_iterations = 100
    for _ in range(num_iterations):
        torch.cuda.synchronize() if device == 'cuda' else None
        start_time = time.time()
        
        with torch.no_grad():
            _ = model(input_tensor)
        
        torch.cuda.synchronize() if device == 'cuda' else None
        end_time = time.time()
        
        times.append((end_time - start_time) * 1000)  # ms
    
    mean_time = np.mean(times)
    std_time = np.std(times)
    min_time = np.min(times)
    max_time = np.max(times)
    median_time = np.median(times)
    
    print(f"Mean inference time: {mean_time:.2f} Â± {std_time:.2f} ms")
    print(f"Throughput: {1000/mean_time:.2f} images/sec")
    
    # æµ‹è¯•ä¸åŒbatch sizeçš„ååé‡
    print("\nMeasuring throughput for different batch sizes...")
    batch_sizes = [1, 4, 8, 16, 32]
    throughputs = {}
    
    for bs in batch_sizes:
        try:
            input_tensor = torch.randn(bs, 3, 224, 224).to(device)
            
            # Warmup
            for _ in range(5):
                with torch.no_grad():
                    _ = model(input_tensor)
            
            # æµ‹é‡
            torch.cuda.synchronize() if device == 'cuda' else None
            start_time = time.time()
            
            num_batches = max(10, 100 // bs)
            for _ in range(num_batches):
                with torch.no_grad():
                    _ = model(input_tensor)
            
            torch.cuda.synchronize() if device == 'cuda' else None
            end_time = time.time()
            
            total_images = bs * num_batches
            total_time = end_time - start_time
            throughput = total_images / total_time
            
            throughputs[bs] = throughput
            print(f"  Batch size {bs:2d}: {throughput:6.2f} images/sec")
        except RuntimeError as e:
            if 'out of memory' in str(e):
                print(f"  Batch size {bs:2d}: OOM")
                throughputs[bs] = None
            else:
                raise e
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""# æ¨¡å‹å¤æ‚åº¦åˆ†ææŠ¥å‘Š - HyperIQA (ResNet50)

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š æ¨¡å‹ä¿¡æ¯

- **æ¨¡å‹åç§°**: HyperIQA (ResNet50 Backbone)
- **æ¨¡å‹ç±»å‹**: CNN-based (ResNet50 + HyperNetwork)
- **æ€»å‚æ•°é‡**: {total_params:,} ({total_params/1e6:.2f}M)
- **å¯è®­ç»ƒå‚æ•°**: {trainable_params:,} ({trainable_params/1e6:.2f}M)
- **è¾“å…¥å°ºå¯¸**: 224Ã—224Ã—3
- **æµ‹è¯•è®¾å¤‡**: {device}

## ğŸ’» è®¡ç®—å¤æ‚åº¦

- **FLOPs**: {flops_str}
- **Parameters**: {total_params/1e6:.2f}M

## â±ï¸ æ¨ç†æ—¶é—´

**å•å¼ å›¾ç‰‡æ¨ç†æ—¶é—´** (224Ã—224):

- **å¹³å‡å€¼**: {mean_time:.2f} ms
- **æ ‡å‡†å·®**: {std_time:.2f} ms
- **æœ€å°å€¼**: {min_time:.2f} ms
- **æœ€å¤§å€¼**: {max_time:.2f} ms
- **ä¸­ä½æ•°**: {median_time:.2f} ms

## ğŸš€ ååé‡

| Batch Size | ååé‡ (images/sec) |
|-----------|---------------------|
"""
    
    for bs in batch_sizes:
        if throughputs[bs] is not None:
            report += f"| {bs} | {throughputs[bs]:.2f} |\n"
        else:
            report += f"| {bs} | OOM |\n"
    
    report += """
## ğŸ“ è¯´æ˜

- æœ¬æŠ¥å‘Šåˆ†æçš„æ˜¯åŸå§‹HyperIQAæ¨¡å‹ï¼ˆä½¿ç”¨ResNet50ä½œä¸ºbackboneï¼‰
- FLOPs (Floating Point Operations): æµ®ç‚¹è¿ç®—æ•°ï¼Œè¡¡é‡è®¡ç®—å¤æ‚åº¦
- æ¨ç†æ—¶é—´ï¼šå‰å‘ä¼ æ’­ä¸€æ¬¡æ‰€éœ€çš„æ—¶é—´
- ååé‡ï¼šå•ä½æ—¶é—´å†…å¯ä»¥å¤„ç†çš„å›¾ç‰‡æ•°é‡
- æµ‹è¯•ä½¿ç”¨äº† 10 æ¬¡ warmup å’Œ 100 æ¬¡è¿­ä»£æ¥è·å¾—ç¨³å®šçš„æµ‹é‡ç»“æœ
"""
    
    # ä¿å­˜æŠ¥å‘Š
    output_path = '/root/Perceptual-IQA-CS3324/complexity/complexity_results_resnet50.md'
    with open(output_path, 'w') as f:
        f.write(report)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

if __name__ == '__main__':
    analyze_resnet_complexity()
