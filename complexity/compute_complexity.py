#!/usr/bin/env python3
"""
æ¨¡å‹å¤æ‚åº¦åˆ†æè„šæœ¬
è®¡ç®— FLOPsã€å‚æ•°é‡ã€æ¨ç†æ—¶é—´å’Œååé‡
"""

import torch
import torch.nn as nn
import time
import numpy as np
from PIL import Image
import sys
import os
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from smart_iqa.models import smart_iqa as models
from torchvision import transforms


def load_model(checkpoint_path, model_size='base', device='cuda', use_attention=None):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"Loading model from: {checkpoint_path}")
    
    # åŠ è½½æƒé‡ä»¥æ£€æµ‹æ˜¯å¦åŒ…å«attention
    checkpoint = torch.load(checkpoint_path, map_location=device)
    if 'model_hyper' in checkpoint:
        state_dict = checkpoint['model_hyper']
    else:
        state_dict = checkpoint
    
    # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦åŒ…å«attention
    if use_attention is None:
        has_attention = any('multiscale_attention' in key for key in state_dict.keys())
        print(f"Auto-detected attention: {has_attention}")
    else:
        has_attention = use_attention
        print(f"Using manual attention setting: {has_attention}")
    
    # åˆ›å»ºæ¨¡å‹
    model = models.HyperNet(
        16, 112, 224, 112, 56, 28, 14, 7,
        use_multiscale=True,
        use_attention=has_attention,
        drop_path_rate=0.3,
        dropout_rate=0.4,
        model_size=model_size
    ).to(device)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(state_dict)
    
    model.eval()
    print(f"Model loaded successfully (model_size={model_size}, attention={has_attention})")
    return model


def load_image(image_path, device='cuda'):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡"""
    print(f"\nLoading image: {image_path}")
    
    # åŠ è½½å›¾ç‰‡
    img = Image.open(image_path).convert('RGB')
    print(f"Original image size: {img.size}")
    
    # é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    img_tensor = transform(img).unsqueeze(0).to(device)  # [1, 3, 224, 224]
    print(f"Preprocessed tensor shape: {img_tensor.shape}")
    
    return img_tensor, img


def count_parameters(model):
    """ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return total_params, trainable_params


def compute_flops_ptflops(model, input_size=(3, 224, 224)):
    """ä½¿ç”¨ ptflops è®¡ç®— FLOPs"""
    try:
        from ptflops import get_model_complexity_info
        
        print("\n" + "="*80)
        print("Computing FLOPs using ptflops...")
        print("="*80)
        
        macs, params = get_model_complexity_info(
            model, input_size, 
            as_strings=True,
            print_per_layer_stat=False,  # è®¾ä¸º True å¯ä»¥çœ‹æ¯å±‚çš„è¯¦ç»†ä¿¡æ¯
            verbose=False
        )
        
        return macs, params
    except ImportError:
        print("ptflops not installed. Install with: pip install ptflops")
        return None, None
    except Exception as e:
        print(f"Error with ptflops: {e}")
        return None, None


def compute_flops_thop(model, input_tensor):
    """ä½¿ç”¨ thop è®¡ç®— FLOPs"""
    try:
        from thop import profile, clever_format
        
        print("\n" + "="*80)
        print("Computing FLOPs using thop...")
        print("="*80)
        
        # å¤åˆ¶æ¨¡å‹åˆ° CPU ä»¥é¿å… CUDA é—®é¢˜
        model_cpu = model.cpu()
        input_cpu = input_tensor.cpu()
        
        flops, params = profile(model_cpu, inputs=(input_cpu,), verbose=False)
        flops, params = clever_format([flops, params], "%.3f")
        
        # ç§»å› GPU
        model.cuda()
        
        return flops, params
    except ImportError:
        print("thop not installed. Install with: pip install thop")
        return None, None
    except Exception as e:
        print(f"Error with thop: {e}")
        return None, None


def measure_inference_time(model, input_tensor, num_warmup=10, num_iterations=100):
    """æµ‹é‡æ¨ç†æ—¶é—´"""
    print("\n" + "="*80)
    print(f"Measuring inference time (warmup={num_warmup}, iterations={num_iterations})...")
    print("="*80)
    
    device = next(model.parameters()).device
    
    # Warmup
    print("Warming up...")
    with torch.no_grad():
        for _ in range(num_warmup):
            _ = model(input_tensor)
    
    # åŒæ­¥ CUDA
    if device.type == 'cuda':
        torch.cuda.synchronize()
    
    # æµ‹é‡æ—¶é—´
    print("Measuring...")
    times = []
    with torch.no_grad():
        for _ in range(num_iterations):
            if device.type == 'cuda':
                torch.cuda.synchronize()
            
            start_time = time.time()
            _ = model(input_tensor)
            
            if device.type == 'cuda':
                torch.cuda.synchronize()
            
            end_time = time.time()
            times.append(end_time - start_time)
    
    times = np.array(times)
    
    return {
        'mean': np.mean(times),
        'std': np.std(times),
        'min': np.min(times),
        'max': np.max(times),
        'median': np.median(times)
    }


def measure_throughput(model, input_tensor, batch_sizes=[1, 4, 8, 16, 32], duration=10):
    """æµ‹é‡ä¸åŒ batch size çš„ååé‡"""
    print("\n" + "="*80)
    print(f"Measuring throughput for different batch sizes (duration={duration}s)...")
    print("="*80)
    
    device = next(model.parameters()).device
    results = {}
    
    for bs in batch_sizes:
        try:
            # åˆ›å»º batch
            batch_input = input_tensor.repeat(bs, 1, 1, 1)
            
            # Warmup
            with torch.no_grad():
                for _ in range(5):
                    _ = model(batch_input)
            
            if device.type == 'cuda':
                torch.cuda.synchronize()
            
            # æµ‹é‡
            num_images = 0
            start_time = time.time()
            
            with torch.no_grad():
                while time.time() - start_time < duration:
                    _ = model(batch_input)
                    num_images += bs
                    
                    if device.type == 'cuda':
                        torch.cuda.synchronize()
            
            elapsed_time = time.time() - start_time
            throughput = num_images / elapsed_time
            
            results[bs] = {
                'throughput': throughput,
                'num_images': num_images,
                'elapsed_time': elapsed_time
            }
            
            print(f"  Batch size {bs:2d}: {throughput:6.2f} images/sec "
                  f"({num_images} images in {elapsed_time:.2f}s)")
            
        except RuntimeError as e:
            print(f"  Batch size {bs:2d}: Out of memory")
            results[bs] = None
            break
    
    return results


def print_summary(model_name, model_size, total_params, trainable_params, 
                 flops_info, time_stats, throughput_results):
    """æ‰“å°å¤æ‚åº¦åˆ†ææ€»ç»“"""
    print("\n" + "="*80)
    print("COMPLEXITY ANALYSIS SUMMARY")
    print("="*80)
    
    print(f"\nğŸ“Š Model Information:")
    print(f"  Model Name: {model_name}")
    print(f"  Model Size: {model_size}")
    print(f"  Total Parameters: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"  Trainable Parameters: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    
    print(f"\nğŸ’» Computational Complexity:")
    if flops_info['ptflops']:
        print(f"  FLOPs (ptflops): {flops_info['ptflops'][0]}")
        print(f"  Params (ptflops): {flops_info['ptflops'][1]}")
    if flops_info['thop']:
        print(f"  FLOPs (thop): {flops_info['thop'][0]}")
        print(f"  Params (thop): {flops_info['thop'][1]}")
    
    print(f"\nâ±ï¸  Inference Time (single image, 224x224):")
    print(f"  Mean: {time_stats['mean']*1000:.2f} ms")
    print(f"  Std:  {time_stats['std']*1000:.2f} ms")
    print(f"  Min:  {time_stats['min']*1000:.2f} ms")
    print(f"  Max:  {time_stats['max']*1000:.2f} ms")
    print(f"  Median: {time_stats['median']*1000:.2f} ms")
    
    print(f"\nğŸš€ Throughput:")
    for bs, result in throughput_results.items():
        if result:
            print(f"  Batch size {bs:2d}: {result['throughput']:6.2f} images/sec")
    
    print("\n" + "="*80)


def save_results(output_file, model_name, model_size, total_params, trainable_params,
                flops_info, time_stats, throughput_results, device_info):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# æ¨¡å‹å¤æ‚åº¦åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## ğŸ“Š æ¨¡å‹ä¿¡æ¯\n\n")
        f.write(f"- **æ¨¡å‹åç§°**: {model_name}\n")
        f.write(f"- **æ¨¡å‹è§„æ¨¡**: {model_size}\n")
        f.write(f"- **æ€»å‚æ•°é‡**: {total_params:,} ({total_params/1e6:.2f}M)\n")
        f.write(f"- **å¯è®­ç»ƒå‚æ•°**: {trainable_params:,} ({trainable_params/1e6:.2f}M)\n")
        f.write(f"- **è¾“å…¥å°ºå¯¸**: 224Ã—224Ã—3\n")
        f.write(f"- **æµ‹è¯•è®¾å¤‡**: {device_info}\n\n")
        
        f.write("## ğŸ’» è®¡ç®—å¤æ‚åº¦\n\n")
        if flops_info['ptflops']:
            f.write(f"### ptflops æµ‹é‡ç»“æœ\n")
            f.write(f"- **FLOPs**: {flops_info['ptflops'][0]}\n")
            f.write(f"- **Parameters**: {flops_info['ptflops'][1]}\n\n")
        
        if flops_info['thop']:
            f.write(f"### thop æµ‹é‡ç»“æœ\n")
            f.write(f"- **FLOPs**: {flops_info['thop'][0]}\n")
            f.write(f"- **Parameters**: {flops_info['thop'][1]}\n\n")
        
        f.write("## â±ï¸ æ¨ç†æ—¶é—´\n\n")
        f.write("**å•å¼ å›¾ç‰‡æ¨ç†æ—¶é—´** (224Ã—224):\n\n")
        f.write(f"- **å¹³å‡å€¼**: {time_stats['mean']*1000:.2f} ms\n")
        f.write(f"- **æ ‡å‡†å·®**: {time_stats['std']*1000:.2f} ms\n")
        f.write(f"- **æœ€å°å€¼**: {time_stats['min']*1000:.2f} ms\n")
        f.write(f"- **æœ€å¤§å€¼**: {time_stats['max']*1000:.2f} ms\n")
        f.write(f"- **ä¸­ä½æ•°**: {time_stats['median']*1000:.2f} ms\n\n")
        
        f.write("## ğŸš€ ååé‡\n\n")
        f.write("| Batch Size | ååé‡ (images/sec) | æµ‹è¯•å›¾ç‰‡æ•° | æµ‹è¯•æ—¶é•¿ (s) |\n")
        f.write("|-----------|---------------------|-----------|-------------|\n")
        for bs, result in throughput_results.items():
            if result:
                f.write(f"| {bs} | {result['throughput']:.2f} | "
                       f"{result['num_images']} | {result['elapsed_time']:.2f} |\n")
            else:
                f.write(f"| {bs} | OOM | - | - |\n")
        
        f.write("\n## ğŸ“ è¯´æ˜\n\n")
        f.write("- FLOPs (Floating Point Operations): æµ®ç‚¹è¿ç®—æ•°ï¼Œè¡¡é‡è®¡ç®—å¤æ‚åº¦\n")
        f.write("- æ¨ç†æ—¶é—´ï¼šå‰å‘ä¼ æ’­ä¸€æ¬¡æ‰€éœ€çš„æ—¶é—´\n")
        f.write("- ååé‡ï¼šå•ä½æ—¶é—´å†…å¯ä»¥å¤„ç†çš„å›¾ç‰‡æ•°é‡\n")
        f.write("- æµ‹è¯•ä½¿ç”¨äº† 10 æ¬¡ warmup å’Œ 100 æ¬¡è¿­ä»£æ¥è·å¾—ç¨³å®šçš„æµ‹é‡ç»“æœ\n")
    
    print(f"\nâœ… Results saved to: {output_file}")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Model Complexity Analysis')
    parser.add_argument('--checkpoint', type=str,
                       default="/root/Perceptual-IQA-CS3324/checkpoints/koniq-10k-swin-ranking-alpha0.5_20251221_155013/best_model_srcc_0.9343_plcc_0.9463.pkl",
                       help='Path to model checkpoint')
    parser.add_argument('--image', type=str,
                       default="/root/Perceptual-IQA-CS3324/complexity/example.JPG",
                       help='Path to example image')
    parser.add_argument('--output', type=str,
                       default="/root/Perceptual-IQA-CS3324/complexity/complexity_results.md",
                       help='Output markdown file path')
    parser.add_argument('--model_size', type=str, default='base',
                       choices=['tiny', 'small', 'base'],
                       help='Model size')
    parser.add_argument('--use_attention', action='store_true',
                       help='Use attention fusion (auto-detected if not specified)')
    parser.add_argument('--no_attention', action='store_true',
                       help='Disable attention fusion')
    
    args = parser.parse_args()
    
    # é…ç½®
    checkpoint_path = args.checkpoint
    image_path = args.image
    output_file = args.output
    model_size = args.model_size
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # ç¡®å®šæ˜¯å¦ä½¿ç”¨attention
    if args.use_attention:
        use_attention = True
    elif args.no_attention:
        use_attention = False
    else:
        use_attention = None  # Auto-detect
    
    print("="*80)
    print("MODEL COMPLEXITY ANALYSIS")
    print("="*80)
    print(f"Checkpoint: {checkpoint_path}")
    print(f"Model size: {model_size}")
    print(f"Device: {device}")
    if device == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # 1. åŠ è½½æ¨¡å‹
    model = load_model(checkpoint_path, model_size=model_size, device=device, use_attention=use_attention)
    
    # 2. åŠ è½½å›¾ç‰‡
    input_tensor, original_img = load_image(image_path, device=device)
    
    # 3. ç»Ÿè®¡å‚æ•°é‡
    total_params, trainable_params = count_parameters(model)
    print(f"\nğŸ“Š Parameters:")
    print(f"  Total: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"  Trainable: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    
    # 4. è®¡ç®— FLOPs
    flops_info = {
        'ptflops': compute_flops_ptflops(model, input_size=(3, 224, 224)),
        'thop': compute_flops_thop(model, input_tensor)
    }
    
    # 5. æµ‹é‡æ¨ç†æ—¶é—´
    time_stats = measure_inference_time(model, input_tensor, num_warmup=10, num_iterations=100)
    
    # 6. æµ‹é‡ååé‡
    throughput_results = measure_throughput(model, input_tensor, 
                                           batch_sizes=[1, 4, 8, 16, 32], 
                                           duration=10)
    
    # 7. æ‰“å°æ€»ç»“
    device_info = f"{device}"
    if device == 'cuda':
        device_info += f" ({torch.cuda.get_device_name(0)})"
    
    print_summary(
        model_name="HyperIQA with Swin Transformer",
        model_size=model_size,
        total_params=total_params,
        trainable_params=trainable_params,
        flops_info=flops_info,
        time_stats=time_stats,
        throughput_results=throughput_results
    )
    
    # 8. ä¿å­˜ç»“æœ
    save_results(
        output_file=output_file,
        model_name="HyperIQA with Swin Transformer",
        model_size=model_size,
        total_params=total_params,
        trainable_params=trainable_params,
        flops_info=flops_info,
        time_stats=time_stats,
        throughput_results=throughput_results,
        device_info=device_info
    )
    
    print("\nâœ… Complexity analysis completed!")


if __name__ == "__main__":
    main()

