% Updated Table 1: SOTA Comparison on KonIQ-10k
% - Only methods with verified data from user
% - Bold formatting for best results
% - Sorted by SRCC within each category
% - Data verified on 2024-12-24

\begin{table*}[t]
\centering
\caption{Performance comparison with state-of-the-art methods on KonIQ-10k dataset. Best results are in bold.}
\label{tab:sota_comparison}
\begin{tabular}{lccc}
\hline
Method & Backbone & SRCC & PLCC \\
\hline
\multicolumn{4}{l}{\textit{CNN-based Methods}} \\
WaDIQaM \cite{bosse2017wadiqam} & ResNet18 & 0.797 & 0.805 \\
SFA \cite{li2022sfa} & ResNet50 & 0.856 & 0.872 \\
DBCNN \cite{zhang2018dbcnn} & ResNet50 & 0.875 & 0.884 \\
PQR \cite{zeng2021pqr} & ResNet50 & 0.880 & 0.884 \\
HyperIQA \cite{su2020hyperiq} & ResNet50 & 0.906 & 0.917 \\
\hline
\multicolumn{4}{l}{\textit{Transformer-based Methods}} \\
CLIP-IQA+ \cite{wang2023clipiqa} & CLIP & 0.895 & 0.909 \\
UNIQUE \cite{zhang2021unique} & Swin-Tiny & 0.896 & 0.901 \\
StairIQA \cite{sun2024stairiqa} & ResNet50 & 0.921 & 0.936 \\
MUSIQ \cite{ke2021musiq} & Multi-scale ViT & 0.929 & 0.924 \\
LIQE \cite{zhang2023liqe} & MobileNet-Swin & 0.930 & 0.931 \\
\hline
\multicolumn{4}{l}{\textit{SMART-IQA (Ours)}} \\
Swin-Tiny & Swin-T (28M) & 0.9249 & 0.9360 \\
Swin-Small & Swin-S (50M) & 0.9338 & 0.9455 \\
\textbf{Swin-Base} & \textbf{Swin-B (88M)} & \textbf{0.9378} & \textbf{0.9485} \\
\hline
\end{tabular}
\end{table*}
