%%% ===============================================================================
%%% SMART-IQA Reference Database
%%% ===============================================================================
%%% Usage:
%%% 1. Add BibTeX entries to this file
%%% 2. Cite in text using \cite{key}
%%% 3. Compile: pdflatex -> bibtex -> pdflatex -> pdflatex
%%% ===============================================================================

%%% ===============================================================================
%%% Core IQA Papers
%%% ===============================================================================

@INPROCEEDINGS{su2020hyperiq,
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network}, 
  year={2020},
  volume={},
  number={},
  pages={3664-3673},
  keywords={Distortion;Feature extraction;Image quality;Semantics;Databases;Task analysis;Predictive models},
  doi={10.1109/CVPR42600.2020.00372}
}

@misc{liu2021swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, 
  author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
  year={2021},
  eprint={2103.14030},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2103.14030}, 
}

%%% ===============================================================================
%%% IQA Datasets
%%% ===============================================================================

@article{hosu2020koniq,
  title={KonIQ-10k: An ecologically valid database for deep learning of blind image quality assessment},
  author={Hosu, Vlad and Lin, Hanhe and Sziranyi, Tamas and Saupe, Dietmar},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4041--4056},
  year={2020},
  publisher={IEEE}
}

@INPROCEEDINGS{fang2020perceptual,
  author={Fang, Yuming and Zhu, Hanwei and Zeng, Yan and Ma, Kede and Wang, Zhou},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Perceptual Quality Assessment of Smartphone Photography}, 
  year={2020},
  volume={},
  number={},
  pages={3674-3683},
  keywords={Cameras;Databases;Distortion;Image quality;Photography;Brightness;Computational modeling},
  doi={10.1109/CVPR42600.2020.00373}
}

@INPROCEEDINGS{lin2019kadid,
  author={Lin, Hanhe and Hosu, Vlad and Saupe, Dietmar},
  booktitle={2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)}, 
  title={KADID-10k: A Large-scale Artificially Distorted IQA Database}, 
  year={2019},
  volume={},
  number={},
  pages={1-3},
  keywords={Image quality;Databases;Distortion;Crowdsourcing;Reliability;Correlation;Deep learning;image quality assessment;image quality dataset;crowdsourcing},
  doi={10.1109/QoMEX.2019.8743252}
}

@misc{li2023agiqa,
  title={AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment}, 
  author={Chunyi Li and Zicheng Zhang and Haoning Wu and Wei Sun and Xiongkuo Min and Xiaohong Liu and Guangtao Zhai and Weisi Lin},
  year={2023},
  eprint={2306.04717},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2306.04717}, 
}

%%% ===============================================================================
%%% SOTA IQA Methods
%%% ===============================================================================

@article{talebi2018nima,
  title={NIMA: Neural Image Assessment},
  volume={27},
  ISSN={1941-0042},
  url={http://dx.doi.org/10.1109/TIP.2018.2831899},
  DOI={10.1109/tip.2018.2831899},
  number={8},
  journal={IEEE Transactions on Image Processing},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)},
  author={Talebi, Hossein and Milanfar, Peyman},
  year={2018},
  month=aug, pages={3998–4011} 
}

@misc{ying2020paq2piq,
  title={From Patches to Pictures (PaQ-2-PiQ): Mapping the Perceptual Space of Picture Quality}, 
  author={Zhenqiang Ying and Haoran Niu and Praful Gupta and Dhruv Mahajan and Deepti Ghadiyaram and Alan Bovik},
  year={2019},
  eprint={1912.10088},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1912.10088}, 
}

@misc{ke2021musiq,
  title={MUSIQ: Multi-scale Image Quality Transformer}, 
  author={Junjie Ke and Qifei Wang and Yilin Wang and Peyman Milanfar and Feng Yang},
  year={2021},
  eprint={2108.05997},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2108.05997}, 
}

@misc{golestaneh2022tres,
  title={No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency}, 
  author={S. Alireza Golestaneh and Saba Dadsetan and Kris M. Kitani},
  year={2022},
  eprint={2108.06858},
  archivePrefix={arXiv},
  primaryClass={eess.IV},
  url={https://arxiv.org/abs/2108.06858}, 
}

@misc{yang2022maniqa,
  title={MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment}, 
  author={Sidi Yang and Tianhe Wu and Shuwei Shi and Shanshan Lao and Yuan Gong and Mingdeng Cao and Jiahao Wang and Yujiu Yang},
  year={2022},
  eprint={2204.08958},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2204.08958}, 
}

@misc{zhang2023liqe,
  title={Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective}, 
  author={Weixia Zhang and Guangtao Zhai and Ying Wei and Xiaokang Yang and Kede Ma},
  year={2023},
  eprint={2303.14968},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2303.14968}, 
}

@misc{wu2023qalign,
  title={Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-Defined Levels}, 
  author={Haoning Wu and Zicheng Zhang and Weixia Zhang and Chaofeng Chen and Liang Liao and Chunyi Li and Yixuan Gao and Annan Wang and Erli Zhang and Wenxiu Sun and Qiong Yan and Xiongkuo Min and Guangtao Zhai and Weisi Lin},
  year={2023},
  eprint={2312.17090},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2312.17090}, 
}

%%% ===============================================================================
%%% Transformer Architectures
%%% ===============================================================================

@misc{vaswani2017attention,
  title={Attention Is All You Need}, 
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year={2023},
  eprint={1706.03762},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1706.03762}, 
}

@misc{dosovitskiy2021vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  year={2021},
  eprint={2010.11929},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2010.11929}, 
}

%%% ===============================================================================
%%% Attention Mechanisms
%%% ===============================================================================

@INPROCEEDINGS{hu2018senet,
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Squeeze-and-Excitation Networks}, 
  year={2018},
  volume={},
  number={},
  pages={7132-7141},
  keywords={Computer architecture;Computational modeling;Convolution;Task analysis;Convolutional codes;Adaptation models;Stacking},
  doi={10.1109/CVPR.2018.00745}
}

@misc{woo2018cbam,
  title={CBAM: Convolutional Block Attention Module}, 
  author={Sanghyun Woo and Jongchan Park and Joon-Young Lee and In So Kweon},
  year={2018},
  eprint={1807.06521},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1807.06521}, 
}

%%% ===============================================================================
%%% Loss Functions and Training Strategies
%%% ===============================================================================

@article{zhang2018dbcnn,
  title={Blind Image Quality Assessment Using a Deep Bilinear Convolutional Neural Network},
  volume={30},
  ISSN={1558-2205},
  url={http://dx.doi.org/10.1109/TCSVT.2018.2886771},
  DOI={10.1109/tcsvt.2018.2886771},
  number={1},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)},
  author={Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou},
  year={2020},
  month=jan, pages={36–47} 
}

@ARTICLE{zhang2021unique,
  author={Zhang, Weixia and Ma, Kede and Zhai, Guangtao and Yang, Xiaokang},
  journal={IEEE Transactions on Image Processing}, 
  title={Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and Wild}, 
  year={2021},
  volume={30},
  number={},
  pages={3474-3486},
  keywords={Databases;Distortion;Training;Uncertainty;Predictive models;Image quality;Optimization;Blind image quality assessment;learning-to-rank;uncertainty estimation;gMAD competition},
  doi={10.1109/TIP.2021.3061932}
}

@article{sun2024stairiqa,
  title={Blind quality assessment for in-the-wild images via hierarchical feature fusion and iterative mixed database training},
  author={Sun, Wei and Min, Xiongkuo and Tu, Danyang and Ma, Siwei and Zhai, Guangtao},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2023},
  publisher={IEEE}
}

@article{bosse2017wadiqam,
  title={Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment},
  volume={27},
  ISSN={1941-0042},
  url={http://dx.doi.org/10.1109/TIP.2017.2760518},
  DOI={10.1109/tip.2017.2760518},
  number={1},
  journal={IEEE Transactions on Image Processing},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)},
  author={Bosse, Sebastian and Maniry, Dominique and Muller, Klaus-Robert and Wiegand, Thomas and Samek, Wojciech},
  year={2018},
  month=jan, pages={206–219} 
}

@ARTICLE{zeng2021pqr,
  author={Sui, Xiangjie and Ma, Kede and Yao, Yiru and Fang, Yuming},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Perceptual Quality Assessment of Omnidirectional Images as Moving Camera Videos}, 
  year={2022},
  volume={28},
  number={8},
  pages={3022-3034},
  keywords={Two dimensional displays;Quality assessment;Distortion;Videos;Image coding;Computational modeling;Visualization;Omnidirectional images;perceptual quality assessment;virtual reality},
  doi={10.1109/TVCG.2021.3050888}
}

@INPROCEEDINGS{li2022sfa,
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Blindly Assess Image Quality in the Wild Guided by a Self-Adaptive Hyper Network}, 
  year={2020},
  volume={},
  number={},
  pages={3664-3673},
  keywords={Distortion;Feature extraction;Image quality;Semantics;Databases;Task analysis;Predictive models},
  doi={10.1109/CVPR42600.2020.00372}
}

@misc{wang2023clipiqa,
  title={Exploring CLIP for Assessing the Look and Feel of Images}, 
  author={Jianyi Wang and Kelvin C. K. Chan and Chen Change Loy},
  year={2022},
  eprint={2207.12396},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2207.12396}, 
}

%%% ===============================================================================
%%% Classical Hand-Crafted Methods
%%% ===============================================================================

@ARTICLE{mittal2012brisque,
  author={Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan Conrad},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Image Quality Assessment in the Spatial Domain}, 
  year={2012},
  volume={21},
  number={12},
  pages={4695-4708},
  keywords={Visualization;Humans;Indexes;Prediction algorithms;Nonlinear distortion;Distortion measurement;Blind quality assessment;denoising;natural scene statistics;no reference image quality assessment;spatial domain},
  doi={10.1109/TIP.2012.2214050}
}

@ARTICLE{mittal2013niqe,
  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C.},
  journal={IEEE Signal Processing Letters}, 
  title={Making a “Completely Blind” Image Quality Analyzer}, 
  year={2013},
  volume={20},
  number={3},
  pages={209-212},
  keywords={Image quality;Image processing;Statistical analysis;Feature extraction;Completely blind;distortion free;image quality assessment;no reference},
  doi={10.1109/LSP.2012.2227726}
}


%%% ===============================================================================
%%% ADD YOUR NEW REFERENCES BELOW THIS LINE
%%% ===============================================================================

% AdamW Optimizer
@misc{loshchilov2019adamw,
  title={Decoupled Weight Decay Regularization}, 
  author={Ilya Loshchilov and Frank Hutter},
  year={2019},
  eprint={1711.05101},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1711.05101}, 
}

% Stochastic Depth / Drop Path
@misc{huang2016deep,
  title={Deep Networks with Stochastic Depth}, 
  author={Gao Huang and Yu Sun and Zhuang Liu and Daniel Sedra and Kilian Weinberger},
  year={2016},
  eprint={1603.09382},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1603.09382}, 
}

% Pairwise Fidelity Loss (PieAPP)
@misc{prashnani2018pieapp,
  title={PieAPP: Perceptual Image-Error Assessment through Pairwise Preference}, 
  author={Ekta Prashnani and Hong Cai and Yasamin Mostofi and Pradeep Sen},
  year={2018},
  eprint={1806.02067},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1806.02067}, 
}

% Large Language Models for IQA
@misc{you2025teachinglargelanguagemodels,
  title={Teaching Large Language Models to Regress Accurate Image Quality Scores using Score Distribution}, 
  author={Zhiyuan You and Xin Cai and Jinjin Gu and Tianfan Xue and Chao Dong},
  year={2025},
  eprint={2501.11561},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2501.11561}, 
}

