# **数字图像处理课程项目：图像视觉感知质量评价 (Perceptual-IQA)**

## **1. 项目核心概述**

### **1.1. 核心目标**
构建、训练并评估一个**无参考图像质量评价 (No-Reference Image Quality Assessment, NR-IQA)** 模型。此模型的功能是输入一张图片，输出一个能代表其视觉感知质量的标量分数，而无需与任何“完美”的参考图像进行对比。

### **1.2. 关键评价指标**
模型的性能将通过以下两个核心指标来衡量：
- **SRCC (Spearman Rank Correlation Coefficient)**: 斯皮尔曼等级相关系数，衡量模型预测分数与人类主观评分之间的单调关系。值域为 `[-1, 1]`，越接近 `1` 表示相关性越强。
- **PLCC (Pearson Linear Correlation Coefficient)**: 皮尔逊线性相关系数，衡量模型预测分数与人类主观评分之间的线性关系。值域为 `[-1, 1]`，越接近 `1` 表示线性相关性越强。

### **1.3. 涉及的数据集**
- **主要训练/测试集**: `KonIQ-10k`
- **跨数据集泛化能力测试集**: `SPAQ`, `KADID-10K`, `AGIQA-3K`

---

## **2. 项目执行路线图 (Action Plan)**

我们采用一个高效且稳妥的四阶段策略：**`跑通基线 -> 理解与改进 -> 实验与分析 -> 报告与提交`**。

### **阶段一：环境搭建与基线模型跑通 (WEEKS 1-2)**

**目标**: 成功复现一个参考模型，建立一个坚实的性能基线 (Baseline)，并熟悉整个开发流程。

**行动步骤**:

1.  **选择基线模型**: 强烈建议从 **`Hyper-IQA`** 开始。
    *   **理由**: 架构主流 (Backbone + Head)，性能强大，且非常易于进行后续的修改和实验。
2.  **环境配置**:
    *   使用 `conda` 创建一个新的虚拟环境: `conda create -n dip_iqa python=3.8`
    *   激活环境: `conda activate dip_iqa`
    *   根据 `Hyper-IQA` 的 `requirements.txt` 或 `README.md` 文件，安装所有依赖库，如 `torch`, `torchvision`, `numpy`, `scipy`, `timm` 等。
3.  **数据准备**:
    *   下载课程提供的所有数据集。
    *   根据 `Hyper-IQA` 代码库中数据加载部分的要求，创建正确的文件目录结构。通常需要一个包含图片路径和对应质量分数的 `.csv` 或 `.txt` 文件。
4.  **执行训练与测试**:
    *   **不要修改任何代码**。使用项目作者提供的默认配置文件和命令行参数。
    *   运行训练脚本，监控训练过程，确保损失函数 (Loss) 正常下降。
    *   训练完成后，运行测试脚本，在 `KonIQ-10k` 测试集上评估模型性能。

**成功标准**:
- 在 `KonIQ-10k` 测试集上得到的 SRCC 和 PLCC 结果与原论文或代码库中报告的数值基本一致。
- 达到课程的**硬性指标要求**: `KonIQ-10k` 上 SRCC/PLCC > 0.75，`SPAQ` 上 SRCC/PLCC > 0.7。

---

### **阶段二：模型理解与创新构思 (WEEK 3)**

**目标**: 从“会用”到“理解”，深入剖析基线模型原理，并在此基础上构思有价值的改进点。

**行动步骤**:

1.  **精读论文与代码**:
    *   找到 `Hyper-IQA` 的原始论文，重点理解其核心思想：什么是超网络 (Hyper Network)？它如何根据图像内容自适应地生成卷积核权重？
    *   逐行阅读模型定义、数据处理和训练循环部分的代码，将代码逻辑与论文思想对应起来。
2.  **头脑风暴改进方案 (选择1-2个实现即可)**:
    *   **`[推荐]` 更换骨干网络 (Backbone)**: 将默认的 `ResNet` 替换为更现代或更高效的架构，如 `EfficientNetV2`, `Swin Transformer`, `MobileNetV3`。分析不同 Backbone 在性能和计算复杂度 (FLOPS) 上的差异。
    *   **`[推荐]` 多尺度特征融合**: `Hyper-IQA` 主要使用深层特征。尝试融合来自骨干网络不同阶段的特征图 (Feature Maps)，因为浅层特征富含纹理细节，对评价噪声、模糊等失真可能更有帮助。
    *   **`[可选]` 探索损失函数**: 在 `L1Loss` (MAE) 的基础上，尝试实现课程PPT中提到的 `Rank_LOSS` 或直接优化 SRCC 的损失函数，并比较其对最终排序性能的影响。
    *   **`[可选]` 优化注意力机制**: 如果 Backbone 包含注意力模块，可以研究是否可以对其进行修改，使其更关注与图像质量相关的区域。

---

### **阶段三：实施改进与对比实验 (WEEKS 4-5)**

**目标**: 将构思付诸实践，并通过严谨的对比实验来验证改进的有效性。

**行动步骤**:

1.  **代码实现**:
    *   在基线模型的代码基础上，创建一个新的分支或文件。
    *   实现你在阶段二中构思的改进方案。例如，使用 `timm` 库可以非常方便地替换 Backbone。
2.  **执行对比实验**:
    *   **控制变量**: 确保除了你的改进点之外，其他所有超参数（如学习率、优化器、batch size、训练周期）都与基线模型完全一致。
    *   **全面评估**: 分别使用**基线模型**和你的**改进后模型**在所有四个数据集 (`KonIQ-10k`, `SPAQ`, `KADID-10K`, `AGIQA-3K`) 上进行评估。
3.  **结果记录与分析**:
    *   创建一个表格，清晰地记录所有模型在所有数据集上的 SRCC 和 PLCC 指标。
    *   绘制训练过程中的 Loss 曲线图，比较不同模型的收敛速度和稳定性。
    *   分析实验结果：你的改进是否带来了性能提升？在哪些数据集上提升更明显？为什么？是否存在性能与效率的权衡？

---

### **阶段四：报告撰写与项目提交 (WEEK 6)**

**目标**: 将你的全部工作系统性地整理成一份专业、规范的课程项目报告，并打包所有材料进行提交。

**行动步骤**:

1.  **撰写报告 (使用 IEEE 模板)**:
    *   **摘要 (Abstract)**: 简要介绍项目背景、你的方法和主要成果。
    *   **引言 (Introduction)**: 介绍 NR-IQA 的重要性，并概述本文的工作。
    *   **方法 (Methodology)**:
        *   详细描述 `Hyper-IQA` 基线模型的工作原理。
        *   **重点**: 清晰地阐述你的**创新点/改进点**，最好配上模型结构图进行说明。
    *   **实验 (Experiments)**:
        *   介绍使用的数据集、评价指标 (SRCC/PLCC)。
        *   列出关键的实现细节和超参数设置。
    *   **结果与分析 (Results and Analysis)**:
        *   展示包含所有实验结果的**核心表格**。
        *   插入 Loss 曲线图等可视化结果。
        *   对结果进行深入讨论和分析。
    *   **复杂度分析 (Complexity Analysis)**: 报告模型的 FLOPS 和推理时间。
    *   **结论 (Conclusion)**: 总结你的工作，并可以展望未来的改进方向。
2.  **整理提交材料**:
    *   最终版的 PDF 报告。
    *   包含所有可运行代码、预训练模型权重（如果有）的完整项目文件夹。
3.  **打包与提交**:
    *   将报告和代码打包成一个 `.zip` 文件。
    *   **命名**: `DIP课程项目+姓名+学号.zip`
    *   **提交**: 发送至助教邮箱 `jzhws1@sjtu.edu.cn` 并上传到 **CANVAS**。
    *   **最终截止日期**: **12月25日 23:59**