# Benchmark æ¨¡åž‹ç»„ç»‡æŒ‡å—

## 2ï¸âƒ£ å…¶ä»–æ¨¡åž‹ Benchmark çš„ç»„ç»‡æ–¹å¼

### å­¦æœ¯é¡¹ç›®ä¸­çš„æ ‡å‡†åšæ³•

åœ¨å­¦æœ¯ç ”ç©¶ä¸­ï¼Œé€šå¸¸éœ€è¦ä¸Žå…¶ä»– SOTA æ¨¡åž‹è¿›è¡Œå¯¹æ¯”ã€‚æœ‰ä»¥ä¸‹å‡ ç§ç»„ç»‡æ–¹å¼ï¼š

---

## æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| **A. åŒä»“åº“ç‹¬ç«‹ç›®å½•** | ä¾¿äºŽç®¡ç†ã€ç»Ÿä¸€çŽ¯å¢ƒ | å¯èƒ½ä»£ç é£Žæ ¼ä¸ä¸€è‡´ | ç®€å•è°ƒç”¨ã€è½»é‡å¯¹æ¯” âœ… |
| **B. å•ç‹¬ä»“åº“** | å®Œå…¨ç‹¬ç«‹ã€æ¸…æ™° | çŽ¯å¢ƒç®¡ç†å¤æ‚ | å¤§åž‹ç‹¬ç«‹å®žçŽ° |
| **C. Git Submodules** | ç‰ˆæœ¬æŽ§åˆ¶æ¸…æ™° | å­¦ä¹ æ›²çº¿é™¡ | ä¾èµ–å¤–éƒ¨ä»“åº“ |
| **D. æ··åˆæ–¹å¼** | çµæ´» | éœ€è¦è‰¯å¥½æ–‡æ¡£ | å¤æ‚é¡¹ç›® |

---

## ðŸŒŸ æŽ¨èæ–¹æ¡ˆï¼šåŒä»“åº“ç‹¬ç«‹ç›®å½•ï¼ˆæ–¹æ¡ˆ Aï¼‰

### ä¸ºä»€ä¹ˆæŽ¨èè¿™ç§æ–¹å¼ï¼Ÿ

1. âœ… **ä¾¿äºŽå¯¹æ¯”**ï¼šæ‰€æœ‰æ¨¡åž‹åœ¨åŒä¸€æ•°æ®é›†ä¸Šæµ‹è¯•ï¼ŒçŽ¯å¢ƒä¸€è‡´
2. âœ… **æ˜“äºŽç®¡ç†**ï¼šç»Ÿä¸€çš„ä¾èµ–ã€ç»Ÿä¸€çš„æ•°æ®è·¯å¾„
3. âœ… **æŠ¥å‘Šå‹å¥½**ï¼šä¸€ä¸ªä»“åº“åŒ…å«æ‰€æœ‰å®žéªŒï¼Œä¾¿äºŽå†™è®ºæ–‡
4. âœ… **ä»£ç å¤ç”¨**ï¼šå¯ä»¥å…±äº« `data_loader.py`ã€`folders.py` ç­‰å·¥å…·
5. âœ… **å­¦æœ¯è§„èŒƒ**ï¼šé¡¶ä¼šè®ºæ–‡å¸¸è§åšæ³•ï¼ˆCVPR/ICCV/NeurIPSï¼‰

---

## ðŸ“ æŽ¨èçš„ç›®å½•ç»“æž„

```
Perceptual-IQA-CS3324/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data_loader.py           # å…±äº«çš„æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ folders.py               # å…±äº«çš„æ•°æ®é›†å¤„ç†
â”‚
â”œâ”€â”€ train_test_IQA.py        # åŽŸå§‹ HyperIQA (ResNet-50)
â”œâ”€â”€ HyerIQASolver.py
â”œâ”€â”€ models.py
â”‚
â”œâ”€â”€ train_swin.py            # æ”¹è¿›çš„ HyperIQA (Swin Transformer) â­ ä½ çš„æ–¹æ³•
â”œâ”€â”€ HyperIQASolver_swin.py
â”œâ”€â”€ models_swin.py
â”‚
â”œâ”€â”€ benchmarks/              # å…¶ä»– SOTA æ¨¡åž‹å¯¹æ¯” âœ¨ æ–°å¢ž
â”‚   â”œâ”€â”€ README.md           # Benchmark ä½¿ç”¨è¯´æ˜Ž
â”‚   â”‚
â”‚   â”œâ”€â”€ maniqa/             # MANIQA æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ train_maniqa.py
â”‚   â”‚   â”œâ”€â”€ test_maniqa.py
â”‚   â”‚   â”œâ”€â”€ model_maniqa.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ musiq/              # MUSIQ æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ train_musiq.py
â”‚   â”‚   â”œâ”€â”€ test_musiq.py
â”‚   â”‚   â”œâ”€â”€ model_musiq.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ clipiqa/            # CLIP-IQA+ æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ test_clipiqa.py
â”‚   â”‚   â”œâ”€â”€ model_clipiqa.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ results/            # Benchmark ç»“æžœæ±‡æ€»
â”‚       â”œâ”€â”€ benchmark_results.csv
â”‚       â””â”€â”€ comparison_plots.py
â”‚
â”œâ”€â”€ checkpoints/            # æ¨¡åž‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                   # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ complexity/             # å¤æ‚åº¦åˆ†æž
â”œâ”€â”€ docs/                   # æ–‡æ¡£
â”‚   â”œâ”€â”€ EXPERIMENT_COMMANDS.md
â”‚   â”œâ”€â”€ ABLATION_STUDY_CORRECTED.md
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ results/                # æœ€ç»ˆç»“æžœï¼ˆè®ºæ–‡ç”¨ï¼‰
    â”œâ”€â”€ main_results.csv
    â”œâ”€â”€ ablation_results.csv
    â”œâ”€â”€ benchmark_comparison.csv
    â””â”€â”€ figures/
```

---

## ðŸ“ å…·ä½“å®žæ–½æ­¥éª¤

### Step 1: åˆ›å»º benchmarks ç›®å½•

```bash
cd /root/Perceptual-IQA-CS3324
mkdir -p benchmarks/results
```

### Step 2: åˆ›å»º Benchmark README

```bash
cat > benchmarks/README.md << 'EOF'
# Benchmark Models

This directory contains implementations and evaluation code for 
state-of-the-art IQA models used for comparison.

## Models Included

1. **MANIQA** (CVPR 2022)
   - Paper: Multi-dimension Attention Network for No-reference Image Quality Assessment
   - Directory: `maniqa/`

2. **MUSIQ** (ICCV 2021)
   - Paper: Multi-scale Image Quality Transformer
   - Directory: `musiq/`

3. **CLIP-IQA+** (arXiv 2023)
   - Paper: Exploring CLIP for Assessing Image Quality
   - Directory: `clipiqa/`

## Usage

See individual model directories for specific usage instructions.

## Results

Benchmark comparison results are available in `results/benchmark_results.csv`.
EOF
```

### Step 3: ä¸ºæ¯ä¸ª Benchmark æ¨¡åž‹åˆ›å»ºç‹¬ç«‹ç›®å½•

ä»¥ MANIQA ä¸ºä¾‹ï¼š

```bash
mkdir -p benchmarks/maniqa
cd benchmarks/maniqa

# åˆ›å»ºæµ‹è¯•è„šæœ¬æ¨¡æ¿
cat > test_maniqa.py << 'EOF'
"""
Test MANIQA on KonIQ-10k dataset
Using official pretrained weights or train from scratch
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# å¯ä»¥å¯¼å…¥é¡¹ç›®æ ¹ç›®å½•çš„å…±äº«æ¨¡å—
import data_loader
import folders

# MANIQA ç‰¹å®šçš„ä»£ç 
# ...

if __name__ == '__main__':
    print("Testing MANIQA on KonIQ-10k...")
    # Your code here
EOF

# åˆ›å»º README
cat > README.md << 'EOF'
# MANIQA Benchmark

## Setup

```bash
pip install timm scipy
```

## Test on KonIQ-10k

```bash
python test_maniqa.py --dataset koniq-10k --model_path pretrained/maniqa.pth
```

## Results

| Dataset | SRCC | PLCC |
|---------|------|------|
| KonIQ-10k | 0.9XX | 0.9XX |

## Citation

```
@inproceedings{maniqa2022,
  title={Multi-dimension Attention Network for No-reference Image Quality Assessment},
  author={...},
  booktitle={CVPR},
  year={2022}
}
```
EOF
```

---

## ðŸ”§ å…±äº«æ¨¡å—çš„ä½¿ç”¨

### æ–¹æ³• 1: ç›´æŽ¥å¯¼å…¥ï¼ˆæŽ¨èï¼‰

åœ¨ benchmark ä»£ç ä¸­ï¼š

```python
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

# çŽ°åœ¨å¯ä»¥å¯¼å…¥é¡¹ç›®æ ¹ç›®å½•çš„æ¨¡å—
from data_loader import DataLoader
from folders import Koniq_10kFolder
```

### æ–¹æ³• 2: ç›¸å¯¹å¯¼å…¥

```python
# åœ¨ benchmarks/maniqa/test_maniqa.py ä¸­
from ...data_loader import DataLoader  # ä¸¤çº§å‘ä¸Š
```

### æ–¹æ³• 3: è½¯é“¾æŽ¥ï¼ˆé«˜çº§ï¼‰

```bash
cd benchmarks/maniqa
ln -s ../../data_loader.py .
ln -s ../../folders.py .
```

---

## ðŸ“Š Benchmark ç»“æžœæ±‡æ€»

### åˆ›å»ºç»Ÿä¸€çš„ç»“æžœæ–‡ä»¶

```bash
cat > benchmarks/results/benchmark_results.csv << 'EOF'
Model,Backbone,Params(M),FLOPs(G),SRCC,PLCC,Year,Venue
HyperIQA (Original),ResNet-50,48.3,12,0.9009,0.9170,2020,CVPR
HyperIQA (Ours),Swin-Base,88.8,18,0.9336,0.9464,2025,-
MANIQA,ViT-B,TBD,TBD,TBD,TBD,2022,CVPR
MUSIQ,Transformer,TBD,TBD,TBD,TBD,2021,ICCV
CLIP-IQA+,CLIP ViT-L,TBD,TBD,TBD,TBD,2023,arXiv
EOF
```

---

## ðŸŽ¯ å…·ä½“æ¨¡åž‹çš„èŽ·å–å’Œé›†æˆ

### é€‰é¡¹ 1: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹ï¼ˆæŽ¨èï¼‰

```python
# benchmarks/maniqa/test_maniqa.py
import torch
from torchvision import transforms

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡åž‹
model = torch.hub.load('repo', 'model', pretrained=True)

# æˆ–è€…ä»Žæœ¬åœ°åŠ è½½
model.load_state_dict(torch.load('pretrained/maniqa.pth'))

# æµ‹è¯•
model.eval()
# ...
```

### é€‰é¡¹ 2: Clone å®˜æ–¹ä»“åº“åˆ° external/

```bash
mkdir -p external
cd external

# Clone å®˜æ–¹å®žçŽ°
git clone https://github.com/IIGROUP/MANIQA.git
git clone https://github.com/google/musiq.git

# åœ¨ benchmarks/ ä¸­åˆ›å»ºç®€å•çš„åŒ…è£…è„šæœ¬
cd ../benchmarks/maniqa
cat > test_maniqa.py << 'EOF'
import sys
sys.path.append('../../external/MANIQA')

from MANIQA.model import MANIQA
# ä½¿ç”¨å®˜æ–¹ä»£ç 
EOF
```

### é€‰é¡¹ 3: Git Submodulesï¼ˆé«˜çº§ï¼‰

```bash
cd external
git submodule add https://github.com/IIGROUP/MANIQA.git
git submodule update --init --recursive
```

---

## ðŸ“ˆ ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

### åˆ›å»ºå¯è§†åŒ–è„šæœ¬

```python
# benchmarks/results/comparison_plots.py
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# è¯»å–ç»“æžœ
df = pd.read_csv('benchmark_results.csv')

# SRCC å¯¹æ¯”æŸ±çŠ¶å›¾
plt.figure(figsize=(10, 6))
plt.bar(df['Model'], df['SRCC'])
plt.xlabel('Model')
plt.ylabel('SRCC')
plt.title('Performance Comparison on KonIQ-10k')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('srcc_comparison.png', dpi=300)

# å‚æ•°é‡ vs æ€§èƒ½æ•£ç‚¹å›¾
plt.figure(figsize=(10, 6))
plt.scatter(df['Params(M)'], df['SRCC'], s=100)
for i, model in enumerate(df['Model']):
    plt.annotate(model, (df['Params(M)'][i], df['SRCC'][i]))
plt.xlabel('Parameters (M)')
plt.ylabel('SRCC')
plt.title('Model Complexity vs Performance')
plt.tight_layout()
plt.savefig('complexity_vs_performance.png', dpi=300)
```

---

## ðŸ“ è®ºæ–‡ä¸­çš„å¼•ç”¨æ–¹å¼

### è¡¨æ ¼ç¤ºä¾‹

```latex
\begin{table}[t]
\centering
\caption{Comparison with State-of-the-Art Methods on KonIQ-10k}
\begin{tabular}{lcccc}
\toprule
Method & Backbone & Params & SRCC & PLCC \\
\midrule
HyperIQA (2020) & ResNet-50 & 48M & 0.906 & 0.917 \\
MUSIQ (2021) & Transformer & 30M & 0.917 & 0.926 \\
MANIQA (2022) & ViT-B & 45M & 0.920 & 0.930 \\
\midrule
\textbf{Ours} & Swin-Base & 89M & \textbf{0.9336} & \textbf{0.9464} \\
\bottomrule
\end{tabular}
\end{table}
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ä¾èµ–ç®¡ç†

å¦‚æžœä¸åŒæ¨¡åž‹éœ€è¦ä¸åŒä¾èµ–ï¼š

```bash
# ä¸»é¡¹ç›®ä¾èµ–
requirements.txt

# Benchmark ç‰¹å®šä¾èµ–
benchmarks/maniqa/requirements.txt
benchmarks/musiq/requirements.txt
```

### 2. æ•°æ®é›†è·¯å¾„

ç¡®ä¿æ‰€æœ‰ benchmark ä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†è·¯å¾„ï¼š

```python
# åœ¨ benchmarks/ ä¸­åˆ›å»º config.py
import os

# ç»Ÿä¸€çš„æ•°æ®é›†è·¯å¾„
KONIQ_PATH = os.path.join(os.path.dirname(__file__), '../koniq-10k')
SPAQ_PATH = os.path.join(os.path.dirname(__file__), '../spaq-test')
```

### 3. è¯„ä¼°åè®®ä¸€è‡´æ€§

- âœ… ä½¿ç”¨ç›¸åŒçš„ train/test split
- âœ… ä½¿ç”¨ç›¸åŒçš„è¯„ä¼°æŒ‡æ ‡ (SRCC, PLCC)
- âœ… ä½¿ç”¨ç›¸åŒçš„å›¾åƒåˆ†è¾¨çŽ‡
- âœ… è®°å½•æµ‹è¯•æ—¶çš„å‚æ•°è®¾ç½®

---

## ðŸŽ¯ æŽ¨èçš„ Benchmark æ¨¡åž‹åˆ—è¡¨

### IQA é¢†åŸŸ SOTA æ¨¡åž‹ï¼ˆ2020-2024ï¼‰

| æ¨¡åž‹ | å¹´ä»½ | ä¼šè®® | GitHub | æŽ¨èç¨‹åº¦ |
|------|------|------|--------|---------|
| **HyperIQA** | 2020 | CVPR | [link](https://github.com/SSL92/hyperIQA) | â­â­â­â­â­ (ä½ çš„ baseline) |
| **MUSIQ** | 2021 | ICCV | [link](https://github.com/google-research/musiq) | â­â­â­â­â­ |
| **TReS** | 2022 | WACV | [link](https://github.com/isalirezag/TReS) | â­â­â­â­ |
| **MANIQA** | 2022 | CVPR | [link](https://github.com/IIGROUP/MANIQA) | â­â­â­â­â­ |
| **CLIP-IQA+** | 2023 | arXiv | [link](https://github.com/IceClear/CLIP-IQA) | â­â­â­â­ |
| **Q-Align** | 2023 | arXiv | [link](https://github.com/Q-Future/Q-Align) | â­â­â­â­â­ (VLM-based) |
| **LIQE** | 2023 | arXiv | [link](https://github.com/zwx8981/LIQE) | â­â­â­â­ |

### é€‰æ‹©å»ºè®®

**å¿…é€‰ï¼ˆè‡³å°‘2-3ä¸ªï¼‰**ï¼š
1. **MANIQA** - 2022 CVPR, ViT-based, æ€§èƒ½å¼º
2. **MUSIQ** - 2021 ICCV, Transformer, Google å‡ºå“
3. **CLIP-IQA+** - 2023, åŸºäºŽ CLIP çš„æ–¹æ³•ï¼ˆVLMï¼‰

**å¯é€‰**ï¼š
4. TReS - å¦‚æžœæƒ³å¯¹æ¯”åŸºäºŽ Transformer çš„æ–¹æ³•
5. Q-Align - å¦‚æžœæƒ³å¯¹æ¯”å¤§æ¨¡åž‹æ–¹æ³•ï¼ˆä½†å¯èƒ½å¤ªæ–°ï¼‰

---

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»º benchmarks ç›®å½•ç»“æž„

```bash
cd /root/Perceptual-IQA-CS3324
bash << 'EOF'
mkdir -p benchmarks/{maniqa,musiq,clipiqa,results}
touch benchmarks/README.md
touch benchmarks/results/benchmark_results.csv
EOF
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡åž‹ï¼ˆç¤ºä¾‹ï¼‰

```bash
cd benchmarks
mkdir pretrained
# ä¸‹è½½ MANIQA é¢„è®­ç»ƒæƒé‡
wget https://example.com/maniqa_koniq.pth -O pretrained/maniqa_koniq.pth
```

### 3. æµ‹è¯• benchmark

```bash
cd maniqa
python test_maniqa.py --dataset koniq-10k --model_path ../pretrained/maniqa_koniq.pth
```

---

## ðŸ“š æ€»ç»“

### æŽ¨èåšæ³• âœ…

1. **åœ¨åŒä¸€ä»“åº“ä¸­åˆ›å»º `benchmarks/` ç›®å½•**
2. **æ¯ä¸ªæ¨¡åž‹ä¸€ä¸ªå­ç›®å½•**ï¼ˆmaniqa/, musiq/, clipiqa/ï¼‰
3. **å…±äº«æ•°æ®åŠ è½½å’Œè¯„ä¼°ä»£ç **
4. **ç»Ÿä¸€çš„ç»“æžœè®°å½•æ ¼å¼** (CSV)
5. **æ¸…æ™°çš„ README å’Œæ–‡æ¡£**

### ä¸æŽ¨èåšæ³• âŒ

1. âŒ æ¯ä¸ªæ¨¡åž‹å•ç‹¬ clone åˆ°ä¸åŒç›®å½•
2. âŒ æ²¡æœ‰ç»Ÿä¸€çš„è¯„ä¼°åè®®
3. âŒ ç»“æžœåˆ†æ•£åœ¨å„å¤„éš¾ä»¥å¯¹æ¯”
4. âŒ ä¾èµ–å†²çªå¯¼è‡´çŽ¯å¢ƒæ··ä¹±

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åŽæ›´æ–°**: December 20, 2025  
**é€‚ç”¨åœºæ™¯**: å­¦æœ¯é¡¹ç›®ã€è®ºæ–‡å¯¹æ¯”å®žéªŒ

