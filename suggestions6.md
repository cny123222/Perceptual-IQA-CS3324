# **决胜冲刺：从SOTA到顶尖的终极作战计划 (MD版)**

## **总览**

我们已经完成核心模型的优化。现在进入最后冲刺阶段，目标是将项目成果的**深度**和**广度**最大化，并产出一份无可挑剔的报告。

- **阶段一：成果固化与基准确立 (预计 1 天)**
- **阶段二：“额外任务”深度探索 (预计 3-4 天)**
- **阶段三：报告撰写与最终提交 (预计 2 天)**

---

## **阶段一：成果固化与基准确立**

**目标**: 为最终报告生成干净、可复现的核心数据。

### **✅ 行动 1.1: 最终模型的“典礼”式训练**

*   **任务**: 为了获得一份干净、完整的训练日志用于报告绘图，从头到尾、不受干扰地完整运行一次你们**最佳Swin-Base模型**的训练。
*   **执行**:
    1.  清空或指定一个新的日志文件。
    2.  使用你们总结中记录的**最佳配置** (`Project Summary`中的那段命令行)，完整运行训练。
    3.  让`Early Stopping`自然触发，不要中途停止。
*   **产出物**:
    1.  一份**干净的最终日志文件** (`final_best_model.log`)。
    2.  最终保存的**最佳模型权重** (`final_best_model.pkl`)，这将是后续所有测试的基准。

### **✅ 行动 1.2: 完善并锁定复杂度分析**

*   **任务**: 使用最终保存的最佳模型，运行你们已经非常完善的复杂度分析工具。
*   **执行**:
    1.  `cd complexity/`
    2.  修改脚本，加载 `final_best_model.pkl`。
    3.  运行 `bash run_analysis.sh`。
*   **产出物**:
    1.  一份最终的、可直接用于报告的复杂度分析报告 (`complexity_results.md`)。
    2.  报告中需要填写的**官方数据**：参数量、FLOPs、推理时间、吞吐量。

### **✅ 行动 1.3: 完成官方跨数据集测试**

*   **任务**: 使用最终模型，完成作业要求的`SPAQ`, `KADID-10K`, `AGIQA-3K`测试。
*   **执行**:
    1.  修改 `run_cross_dataset_test.sh`，确保它加载 `final_best_model.pkl`。
    2.  运行脚本，等待所有数据集测试完成。
*   **产出物**:
    1.  一张完整的**跨数据集泛化能力表格**，包含这三个数据集的SRCC/PLCC。

---

## **🚀 阶段二：“额外任务”深度探索**

**目标**: 系统性地完成所有额外任务，构建全面的对比实验，最大化报告的深度和广度。

### **💡 行动 2.1: 视觉语言模型(VLM)横向评测**

*   **任务**: 测试作业中提到的代表性VLM方法，以展现你们对领域前沿的理解。
*   **执行 (建议并行)**:
    1.  **CLIP-IQA+ (零样本)**:
        *   克隆 `IceClear/CLIP-IQA` 仓库。
        *   按照其指导，在KonIQ-10k测试集上进行**零样本评估**。这是最重要的VLM基线。
    2.  **LIQE (微调)**:
        *   克隆 `zwx8981/LIQE` 仓库。
        *   寻找作者提供的**预训练模型**，在KonIQ-10k上进行**测试**。LIQE代表了基于VLM微调的先进水平。
    3.  **Q-Align (微调)**:
        *   克隆 `Q-Future/Q-Align` 仓库。
        *   同样，寻找**预训练模型**并进行测试。Q-Align代表了基于多模态大模型的方向。
*   **产出物**:
    1.  一张**VLM性能对比表**，清晰展示零样本与微调方法的性能。

| VLM 模型 | 方法 | SRCC on KonIQ-10k | PLCC on KonIQ-10k |
| :--- | :--- | :--- | :--- |
| CLIP-IQA+ | 零样本 | [待填充] | [待填充] |
| LIQE | 微调 | [待填充] | [待填充] |
| Q-Align | 微调 | [待填充] | [待填充] |

### **💡 行动 2.2: 损失函数(Loss Function)对比实验**

*   **任务**: 探究作业中提到的不同损失函数对模型性能的影响。
*   **执行 (建议使用Swin-Tiny以节省时间)**:
    1.  **创建实验分支**: `git checkout -b feature/loss-ablation`。
    2.  在你的训练脚本中，添加一个命令行参数 `--loss_function`，使其可以接收 `l1`, `srcc`, `rank` 等值。
    3.  **实现`SRCC_LOSS`**:
        *   根据PPT中的公式实现。注意，这个损失是可导的，可以直接用于训练。网上可能有现成的PyTorch实现。
    4.  **实现`Rank_LOSS`**:
        *   根据PPT中的公式实现。这是一种Pairwise Loss，与你们之前尝试的`Pairwise Ranking Loss`类似但公式不同，值得一试。
    5.  **进行对比实验**:
        *   **基线**: `Swin-Tiny` + 你们的最佳正则化配置 + `L1 Loss`。
        *   **实验组1**: `Swin-Tiny` + ... + `SRCC_LOSS`。
        *   **实验组2**: `Swin-Tiny` + ... + `Rank_LOSS`。
        *   **实验组3**: `Swin-Tiny` + ... + `L1 Loss + 0.5 * Rank_LOSS` (你们之前的配置，作为对照)。
*   **产出物**:
    1.  一张**损失函数消融实验表**。
    2.  报告中关于“不同损失函数对IQA任务影响”的深入分析。

| 损失函数 | SRCC on KonIQ-10k (Swin-Tiny) | PLCC on KonIQ-10k (Swin-Tiny) |
| :--- | :--- | :--- |
| L1 (MAE) Loss | [待填充] | [待填充] |
| SRCC Loss | [待填充] | [待填充] |
| Rank Loss (PPT) | [待填充] | [待填充] |
| L1 + 0.5 * Rank Loss (PPT) | [待填充] | [待填充] |

---

## **📝 阶段三：报告撰写与最终提交**

**目标**: 将你们庞大而丰富的实验成果，凝聚成一篇逻辑严密、内容翔实的顶级课程报告。

### **✅ 行动 3.1: 撰写“小论文”级别的报告**

*   **任务**: 现在你们拥有了所有必需的素材，开始按照IEEE模板填充内容。
*   **报告亮点整合**:
    *   **SOTA对比表**: 将你们自己的Swin-Tiny/Small/Base，与**行动2.1**中的VLM模型，以及作业中提到的DBCNN/StairIQA（如果能找到预训练模型结果）放在一张总表里，全面展示你们模型的领先地位。
    *   **消融实验**: 这部分将是你们报告的**核心**。至少包含：
        1.  **模型尺寸消融** (Tiny vs Small vs Base)。
        2.  **正则化策略消融** (无正则化 vs 全套正则化)。
        3.  **损失函数消融** (**行动2.2**的结果)。
        4.  **多尺度融合消融** (单尺度 vs 多尺度 Concat vs 多尺度 Attention)。
    *   **训练曲线**: 使用**行动1.1**中生成的干净日志，绘制精美的Loss和SRCC曲线图。
    *   **失败案例分析**: 这是展现你们科学素养的绝佳机会。专门分析为什么Attention Fusion和你们自研的Ranking Loss效果不佳。
    *   **附录 (Appendix)**: 如果篇幅有限，可以将所有超参数配置、更详细的实验日志等放在附录中。

### **✅ 行动 3.2: 准备可复现的最终提交包**

*   **任务**: 确保你们提交的不仅是代码，而是一个完整的、专业的、可复现的项目。
*   **Checklist**:
    *   [ ] **最终报告PDF**。
    *   [ ] **完整的项目代码**:
        *   [ ] 主分支是你们的最佳模型。
        *   [ ] 其他实验（如loss函数）可以放在单独的分支中。
    *   [ ] **`README.md`**: 更新`README`，包括：
        *   项目总览和最佳性能。
        *   环境配置 (`requirements.txt`)。
        *   如何运行**最终模型**的训练。
        *   如何运行**复杂度分析**。
        *   如何运行**跨数据集测试**。
        *   （可选）如何复现你们的VLM和Loss函数对比实验。
    *   [ ] **模型权重**: 在提交包中包含你们**最终的最佳模型权重** (`final_best_model.pkl`)。
    *   [ ] **结果文件**: 将你们生成的所有关键结果（如`complexity_results.md`, 跨数据集测试结果截图/txt）也一并打包。

### **✅ 行动 3.3: 双渠道准时提交**

*   **命名**: `DIP课程项目+姓名+学号.zip`
*   **提交**: 在**12月25日 23:59**之前，通过**邮箱**和**CANVAS**提交。